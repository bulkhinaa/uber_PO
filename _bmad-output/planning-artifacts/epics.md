---
stepsCompleted: [1, 2, 3, 4]
inputDocuments:
  - '/Users/baa/my-bmad-project/UBER_PO/_bmad-output/planning-artifacts/PRD-v0.7.md'
  - '/Users/baa/my-bmad-project/UBER_PO/_bmad-output/planning-artifacts/architecture.md'
  - '/Users/baa/my-bmad-project/UBER_PO/_bmad-output/planning-artifacts/ux-design-specification.md'
architectureStatus: 'complete'
architectureDecisions:
  database_schema: 'relational tables (strict structure)'
  radar_rules: 'in Python code'
  html_storage: 'local /static/artifacts/'
  authentication: 'hardcoded Telegram ID'
  background_jobs: 'APScheduler persistent'
  deployment: 'Railway'
epicsApproved: true
totalEpics: 4
totalStories: 28
storiesCreated: true
validationComplete: true
workflowComplete: true
---

# UBER_PO - Epic Breakdown

## Overview

This document provides the complete epic and story breakdown for UBER_PO, decomposing the requirements from the PRD, UX Design, and Architecture requirements into implementable stories.

## Requirements Inventory

### Functional Requirements

**FR-001: –ü—Ä–æ–µ–∫—Ç—ã –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞**
- –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ –≥–æ–ª–æ—Å–æ–º
- –°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞—ë—Ç —Ä–∞–∑–¥–µ–ª—ã –ø—Ä–æ–µ–∫—Ç–∞ (–ê–Ω–∞–ª–∏—Ç–∏–∫–∞, –ü—Ä–æ–¥—É–∫—Ç, –ë—ç–∫–ª–æ–≥, –†–µ–ª–∏–∑—ã, –í—Å—Ç—Ä–µ—á–∏, –†–µ—à–µ–Ω–∏—è, –†–∏—Å–∫–∏, –ü–æ—Ä—É—á–µ–Ω–∏—è, –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è, –°–ø—Ä–∞–≤–∫–∏/–î–æ–∫—É–º–µ–Ω—Ç—ã)
- –ü–æ–∏—Å–∫ –ø—Ä–æ–µ–∫—Ç–∞/—Ñ–∏—á–∏/–∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞ –≥–æ–ª–æ—Å–æ–º
- AC: –ü—Ä–æ–µ–∫—Ç —Å–æ–∑–¥–∞—ë—Ç—Å—è —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º id –∏ –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º–∏ –ø–∞–ø–∫–∞–º–∏
- AC: –ü–æ–∏—Å–∫ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞ <1 —Å–µ–∫—É–Ω–¥—É, —Ç–æ—á–Ω–æ—Å—Ç—å Top-3 ‚â• 85%
- AC: –ü—Ä–∏ –Ω–µ–æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç Top-3 –≤–∞—Ä–∏–∞–Ω—Ç–∞ –¥–ª—è –≤—ã–±–æ—Ä–∞

**FR-002: Inbox –∏–¥–µ–π**
- –§–∏–∫—Å–∞—Ü–∏—è –∏–¥–µ–∏ –≥–æ–ª–æ—Å–æ–º
- –°–∏—Å—Ç–µ–º–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–¥–µ—é –≤ Inbox –∏–ª–∏ –ø—Ä–∏–≤—è–∑—ã–≤–∞–µ—Ç –∫ –ø—Ä–æ–µ–∫—Ç—É
- –ü—Ä–µ–≤—Ä–∞—â–µ–Ω–∏–µ –∏–¥–µ–∏ –≤ —Ñ–∏—á—É/–¥–æ–∫—É–º–µ–Ω—Ç —á–µ—Ä–µ–∑ workflow
- AC: –ò–¥–µ—è –≤—Å–µ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –¥–∞–∂–µ –ø—Ä–∏ –Ω–µ–ø–æ–ª–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
- AC: –°–∏—Å—Ç–µ–º–∞ —Ñ–∏–∫—Å–∏—Ä—É–µ—Ç –∞—É–¥–∏—Ç —Å–æ–∑–¥–∞–Ω–∏—è/–ª–∏–Ω–∫–æ–≤–∫–∏ –∏–¥–µ–∏ –∫ –ø—Ä–æ–µ–∫—Ç—É

**FR-003: –§–∏—á–∏ (2 –Ω–µ–¥–µ–ª–∏)**
- –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏—á–∏ —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º, —Å—Ç–∞—Ç—É—Å–æ–º, –ø—Ä–∏—á–∏–Ω–æ–π —Å—Ç–∞—Ç—É—Å–∞, –∫–æ–º–∞–Ω–¥–∞–º–∏, PO
- –°–∏—Å—Ç–µ–º–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —Å—Ç–∞—Ç—É—Å–æ–≤ —Ñ–∏—á–∏
- AC: –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∞—É–¥–∏—Ç —Å –ø—Ä–∏—á–∏–Ω–æ–π –∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π
- AC: –°—Ç–∞—Ç—É—Å —Ñ–∏—á–∏ –≤–ª–∏—è–µ—Ç –Ω–∞ Radar –ø—Ä–∞–≤–∏–ª–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, Blocked ‚Üí "–≥–æ—Ä–∏—Ç")

**FR-004: –°–≤—è–∑–∏ (Dependency)**
- "–§–∏—á–∞ A –±–ª–æ–∫–∏—Ä—É–µ—Ç —Ñ–∏—á—É B"
- –°–∏—Å—Ç–µ–º–∞ —É—á–∏—Ç—ã–≤–∞–µ—Ç –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –≤ Radar —Å–≤–æ–¥–∫–∞—Ö
- AC: –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –æ—Ç—Ä–∞–∂–∞—é—Ç—Å—è –≤ Radar —Å –ø—Ä–∏—á–∏–Ω–æ–π –∏ explainability

**FR-005: –†–µ–ª–∏–∑—ã**
- –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–ª–∏–∑–∞, –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ/—É–¥–∞–ª–µ–Ω–∏–µ —Ñ–∏—á, –ø–µ—Ä–µ–Ω–æ—Å —Ä–µ–ª–∏–∑–∞
- –ü–µ—Ä–µ–Ω–æ—Å —Ä–µ–ª–∏–∑–∞ —Ç—Ä–µ–±—É–µ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è (–¥–æ—Ä–æ–≥–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è)
- AC: –ü–µ—Ä–µ–Ω–æ—Å —Ä–µ–ª–∏–∑–∞ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –ø–µ—Ä–µ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ–º
- AC: –°–∏—Å—Ç–µ–º–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∞—É–¥–∏—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π —Ä–µ–ª–∏–∑–∞

**FR-006: –ü—Ä–æ—Ç–æ–∫–æ–ª—ã –≤—Å—Ç—Ä–µ—á**
- –°–∏—Å—Ç–µ–º–∞ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∏–∑ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞: —Ä–µ—à–µ–Ω–∏—è, –ø–æ—Ä—É—á–µ–Ω–∏—è, —Ä–∏—Å–∫–∏, –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–æ–≤
- –í—Å–µ –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è —Å –ø—Ä–∏–≤—è–∑–∫–æ–π –∫ –≤—Å—Ç—Ä–µ—á–µ
- AC: –í—Å–µ extracted —Å—É—â–Ω–æ—Å—Ç–∏ —Å–≤—è–∑–∞–Ω—ã —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–º –≤—Å—Ç—Ä–µ—á–∏
- AC: –°–∏—Å—Ç–µ–º–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∞—É–¥–∏—Ç —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ—à–µ–Ω–∏–π/–ø–æ—Ä—É—á–µ–Ω–∏–π/—Ä–∏—Å–∫–æ–≤

**FR-007: –ü–æ—Ä—É—á–µ–Ω–∏—è + –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è**
- –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Ä—É—á–µ–Ω–∏—è –≥–æ–ª–æ—Å–æ–º —Å –¥–µ–¥–ª–∞–π–Ω–æ–º –∏ –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è–º–∏ (–∑–∞ –¥–µ–Ω—å/2 —á–∞—Å–∞/–∫–∞—Å—Ç–æ–º)
- –°–∏—Å—Ç–µ–º–∞ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è –≤ –∑–∞–¥–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è
- AC: –î–µ–¥–ª–∞–π–Ω –∏ –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏
- AC: –ü—Ä–æ—Å—Ä–æ—á–µ–Ω–Ω—ã–µ –ø–æ—Ä—É—á–µ–Ω–∏—è —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è Radar –∫–∞–∫ "–≥–æ—Ä–∏—Ç"

**FR-008: Radar top-3**
- "–ß—Ç–æ –≥–æ—Ä–∏—Ç?", "–ì–¥–µ —Ä–∏—Å–∫?", "–ß—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å?"
- –°–∏—Å—Ç–µ–º–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç Top-3 items —Å explainability
- AC: –ö–∞–∂–¥—ã–π Radar item —Å–æ–¥–µ—Ä–∂–∏—Ç ‚â•2 –ø—Ä–∏—á–∏–Ω—ã + —Å—Å—ã–ª–∫–∏ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö (rules + entity links)
- AC: Explainability –≤–∫–ª—é—á–∞–µ—Ç: —Å—Ä–∞–±–æ—Ç–∞–≤—à–∏–µ –ø—Ä–∞–≤–∏–ª–∞, –¥–∞—Ç—ã, —Å—Ç–∞—Ç—É—Å—ã, next step

**FR-009: Meeting Prep**
- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –≤—Å—Ç—Ä–µ—á–µ
- –°–∏—Å—Ç–µ–º–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç 1-page prep: —Å—Ç–∞—Ç—É—Å, –≤–æ–ø—Ä–æ—Å—ã, –∫—Ä–∏—Ç–∏—á–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã
- AC: –°–æ–∑–¥–∞—ë—Ç—Å—è Artifact(type=prep) —Å –ø—Ä–∏–≤—è–∑–∫–æ–π –∫ –ø—Ä–æ–µ–∫—Ç—É/–≤—Å—Ç—Ä–µ—á–µ
- AC: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è HTML view —Å –ø—Ä–∏–≤–∞—Ç–Ω–æ–π —Å—Å—ã–ª–∫–æ–π

**FR-010: –°–ø—Ä–∞–≤–∫–∏ –ø–æ –ø—Ä–æ–µ–∫—Ç–∞–º/—Ñ–∏—á–∞–º**
- –°–ø—Ä–∞–≤–∫–∞ –ø–æ –ø—Ä–æ–µ–∫—Ç—É/—Ñ–∏—á–µ
- –°–∏—Å—Ç–µ–º–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç: —Ü–µ–ª—å, –æ–ø–∏—Å–∞–Ω–∏–µ, –º–µ—Ç—Ä–∏–∫–∏, —Å—Ç–∞—Ç—É—Å, —Ä–∏—Å–∫–∏, –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏, —Ä–µ–ª–∏–∑—ã, –∏–∑–º–µ–Ω–µ–Ω–∏—è
- AC: –°–æ–∑–¥–∞—ë—Ç—Å—è Artifact(type=brief)
- AC: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è HTML view —Å –ø—Ä–∏–≤–∞—Ç–Ω–æ–π —Å—Å—ã–ª–∫–æ–π

**FR-011: –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è "–Ω–µ —Ç—Ä–µ–≤–æ–∂—å –º–µ–Ω—è"**
- –§–æ–Ω–æ–≤–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ
- –°–∏—Å—Ç–µ–º–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç one-pager —Å 7 —Ä–∞–∑–¥–µ–ª–∞–º–∏: –≤–æ–ø—Ä–æ—Å, –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã, —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ, —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è, —Ä–∏—Å–∫–∏, –¥–æ–ø—É—â–µ–Ω–∏—è, next steps, –∏—Å—Ç–æ—á–Ω–∏–∫–∏
- AC: –°–∏—Å—Ç–µ–º–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ –¥–æ–ø—É—â–µ–Ω–∏—è —è–≤–Ω–æ
- AC: –°–æ–∑–¥–∞—ë—Ç—Å—è Artifact(type=research) —Å–æ structured format (7 —Ä–∞–∑–¥–µ–ª–æ–≤)

**FR-012: –ú—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**
- –°–∏—Å—Ç–µ–º–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç registry –∞–≥–µ–Ω—Ç–æ–≤, —Ä—É—á–Ω–æ–π –≤—ã–∑–æ–≤, guided workflows, party mode
- –¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞: –∫–∞–∂–¥–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è —Ñ–∏–∫—Å–∏—Ä—É–µ—Ç –∞–≥–µ–Ω—Ç–∞, –≤—Ö–æ–¥—ã, –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã
- Agents/Workflows/Rules —Ö—Ä–∞–Ω—è—Ç—Å—è –∫–∞–∫ code (YAML/JSON)
- AC: –ê—É–¥–∏—Ç –∏ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã –¥–ª—è –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
- AC: –í–µ—Ä—Å–∏–∏ –∫–æ–Ω—Ñ–∏–≥–æ–≤ —Ñ–∏–∫—Å–∏—Ä—É—é—Ç—Å—è –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏

**FR-013: Auto Rendered HTML Artifacts**
- –°–∏—Å—Ç–µ–º–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç HTML view –¥–ª—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤: report, brief, prep, minutes
- –ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –¥–æ—Å—Ç—É–ø–Ω—ã —á–µ—Ä–µ–∑ –ø—Ä–∏–≤–∞—Ç–Ω—ã–µ —Å—Å—ã–ª–∫–∏ —Å TTL=7 –¥–Ω–µ–π
- AC: –ü—Ä–∏–≤–∞—Ç–Ω–∞—è —Å—Å—ã–ª–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç—Ä—É–¥–Ω–æ—É–≥–∞–¥—ã–≤–∞–µ–º—ã–π —Ç–æ–∫–µ–Ω, TTL=7 –¥–Ω–µ–π
- AC: –°–∏—Å—Ç–µ–º–∞ —Ñ–∏–∫—Å–∏—Ä—É–µ—Ç —Å–æ–±—ã—Ç–∏—è `artifact_rendered`, `artifact_viewed` –≤ –∞—É–¥–∏—Ç–µ

**FR-014: Leader Tasks Inbox**
- –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Ä—É—á–µ–Ω–∏—è –æ—Ç —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è
- –°–∏—Å—Ç–µ–º–∞ —Å–æ–∑–¥–∞—ë—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–π inbox –¥–ª—è leader-–ø–æ—Ä—É—á–µ–Ω–∏–π —Å guided review
- Leader P1 –ø–æ—Ä—É—á–µ–Ω–∏—è –≤–ª–∏—è—é—Ç –Ω–∞ Radar —Å –ø–æ–≤—ã—à–µ–Ω–Ω—ã–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º
- AC: Assignment(source=leader, inbox=leader) —Å–æ–∑–¥–∞—ë—Ç—Å—è –ø—Ä–∏ –∫–∞–∂–¥–æ–º leader-–ø–æ—Ä—É—á–µ–Ω–∏–∏
- AC: Leader P1 overdue/‚â§24—á –Ω–µ –ø–æ–¥–∞–≤–ª—è–µ—Ç—Å—è —Å—É–ø—Ä–µ—Å—Å–∏–µ–π –≤ Radar

### NonFunctional Requirements

**NFR-001: Performance**
- API response time < 200ms –¥–ª—è 95th percentile –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ–¥ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–π –Ω–∞–≥—Ä—É–∑–∫–æ–π
- ASR latency < 2 —Å–µ–∫—É–Ω–¥—ã –æ—Ç –ø–æ–ª—É—á–µ–Ω–∏—è voice file –¥–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞
- Radar generation < 5 —Å–µ–∫—É–Ω–¥ –¥–ª—è 20 –ø—Ä–æ–µ–∫—Ç–æ–≤ + 200 —Ñ–∏—á
- –ú–µ—Ç–æ–¥ –∏–∑–º–µ—Ä–µ–Ω–∏—è: APM tracing + performance logs

**NFR-002: Reliability**
- Uptime ‚â• 99.5% –≤ –º–µ—Å—è—á–Ω–æ–º –∏–∑–º–µ—Ä–µ–Ω–∏–∏
- Message delivery guarantee: –∫–∞–∂–¥–æ–µ voice message –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è —Ä–æ–≤–Ω–æ 1 —Ä–∞–∑ (idempotency —á–µ—Ä–µ–∑ ingestion_id)
- Audit durability: EventLog append-only, —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –Ω–∞–≤—Å–µ–≥–¥–∞, —Ä–µ–ø–ª–∏–∫–∞—Ü–∏—è –≤ 3 –¥–∞—Ç–∞—Ü–µ–Ω—Ç—Ä–∞—Ö
- –ú–µ—Ç–æ–¥ –∏–∑–º–µ—Ä–µ–Ω–∏—è: Uptime monitoring (Pingdom) + audit log integrity checks

**NFR-003: Security & Privacy**
- Voice file encryption: AES-256 at rest, TLS 1.3 in transit
- User consent: –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ —Å–æ–≥–ª–∞—Å–∏–µ –ø–µ—Ä–µ–¥ –ø–µ—Ä–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –≥–æ–ª–æ—Å–∞
- Voice retention policy: 30 –¥–Ω–µ–π, –∑–∞—Ç–µ–º –∞–≤—Ç–æ—É–¥–∞–ª–µ–Ω–∏–µ (GDPR compliance)
- Audit trail: end-to-end audit –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–æ–≤ –∫ –¥–∞–Ω–Ω—ã–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, retention 90 –¥–Ω–µ–π
- –ú–µ—Ç–æ–¥ –∏–∑–º–µ—Ä–µ–Ω–∏—è: Security audit + penetration testing + GDPR compliance check

**NFR-004: Scalability**
- 100 concurrent users –±–µ–∑ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏–∏ latency
- 1000 daily messages per user –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –±–µ–∑ queue delays
- PostgreSQL –¥–æ 10M events –≤ EventLog –±–µ–∑ performance degradation (p95 query latency < 500ms)
- –ú–µ—Ç–æ–¥ –∏–∑–º–µ—Ä–µ–Ω–∏—è: Load testing (k6/Locust) + database performance monitoring

**NFR-005: Observability**
- Distributed tracing coverage: 100% –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π (message ‚Üí workflow ‚Üí agent ‚Üí db ‚Üí artifact)
- P95 query latency < 500ms –¥–ª—è trace lookups
- Metrics: ASR accuracy, NLU intent/slot accuracy, Command Success Rate, Context Correctness Rate
- –ú–µ—Ç–æ–¥ –∏–∑–º–µ—Ä–µ–Ω–∏—è: OpenTelemetry + Jaeger/Tempo + Prometheus/Grafana

**NFR-006: Accessibility**
- Text-only fallback mode: –≤—Å–µ voice commands –¥–æ—Å—Ç—É–ø–Ω—ã —á–µ—Ä–µ–∑ text input –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏ —Ä–µ—á–∏
- HTML artifacts WCAG 2.1 AA compliant: screen reader support –¥–ª—è –≤—Å–µ—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
- Alternative input methods: text commands –¥–ª—è –≤—Å–µ—Ö voice commands
- –ú–µ—Ç–æ–¥ –∏–∑–º–µ—Ä–µ–Ω–∏—è: WCAG audit + manual accessibility testing

**NFR-007: Data Residency**
- Data stored in user-specified region (EU/US/Asia)
- No cross-border data transfer –±–µ–∑ explicit consent
- Regional PostgreSQL instances –¥–ª—è compliance
- –ú–µ—Ç–æ–¥ –∏–∑–º–µ—Ä–µ–Ω–∏—è: Infrastructure audit + data flow tracing

### Additional Requirements

**–ò–∑ Architecture (–ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –†–ï–®–ï–ù–ò–Ø –î–õ–Ø MVP):**

**MVP Constraints (2 –Ω–µ–¥–µ–ª–∏):**
- **Timeline:** 2 weeks (14 –¥–Ω–µ–π)
- **Users:** Single user (Artem) ‚Äî hardcoded Telegram ID –≤ .env
- **Developer Experience:** Limited ‚Äî AI-assisted development (Claude –ø–∏—à–µ—Ç –≤–µ—Å—å –∫–æ–¥, Artem —Ç–µ—Å—Ç–∏—Ä—É–µ—Ç)
- **Agents:** GPT-4 with system prompts (–Ω–µ —Å–ª–æ–∂–Ω–∞—è orchestration, –ø—Ä–æ—Å—Ç–æ —Ñ–∞–π–ª—ã prompts/*.txt)
- **HTML Artifacts:** Required (–∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è CEO –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–π)

**Critical Architectural Decisions (–±–ª–æ–∫–∏—Ä—É—é—Ç implementation):**

1. ‚úÖ **Database Schema:** Relational tables (strict structure) ‚Äî PostgreSQL + SQLAlchemy ORM
2. ‚úÖ **Authentication:** Hardcoded Telegram ID –≤ .env (—Ç–æ–ª—å–∫–æ Artem)
3. ‚úÖ **Background Jobs:** APScheduler —Å persistent storage –≤ PostgreSQL (jobs survive restart)
4. ‚úÖ **Deployment:** Railway (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π PostgreSQL, simple deploy, free tier 500 hours/month)

**Important Architectural Decisions (—Ñ–æ—Ä–º–∏—Ä—É—é—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É):**

5. ‚úÖ **Radar Rules Storage:** –í –∫–æ–¥–µ Python (`services/radar.py` ‚Äî –ø—Ä–æ—Å—Ç—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ scoring)
6. ‚úÖ **HTML Artifacts Storage:** –õ–æ–∫–∞–ª—å–Ω–æ –≤ `/static/artifacts/` (–Ω–µ S3, Railway –¥–∞—ë—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ storage)
7. ‚úÖ **Bot Communication Mode:** Polling –¥–ª—è dev (no ngrok), Webhook –¥–ª—è prod (Railway –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Å—Ç—Ä–æ–∏—Ç HTTPS)
8. ‚úÖ **OpenAI Integration:** Direct API calls (openai library, system prompts –≤ —Ñ–∞–π–ª–∞—Ö)
9. ‚úÖ **Error Handling:** Try/Catch —Å graceful degradation + retry logic (3 retries, exponential backoff)

**Deferred Decisions (Post-MVP):**
- ‚ùå Multi-user support (–Ω–µ –Ω—É–∂–Ω–æ –≤ MVP)
- ‚ùå Admin UI –¥–ª—è Radar rules (hardcoded rules –ø—Ä–æ—â–µ)
- ‚ùå S3/Cloudflare R2 –¥–ª—è HTML (–ª–æ–∫–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ)
- ‚ùå Celery + Redis (APScheduler –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ)
- ‚ùå Encryption at rest, GDPR compliance (post-MVP)

**Starter Template & Stack (—Ñ–∏–Ω–∞–ª—å–Ω—ã–π –≤—ã–±–æ—Ä):**
- **Framework:** Flask 3.x (–ø—Ä–æ—â–µ —á–µ–º FastAPI, –º–µ–Ω—å—à–µ boilerplate)
- **Bot Library:** python-telegram-bot v22.6 (async/await)
- **Database:** PostgreSQL + SQLAlchemy 2.0 ORM + Alembic 1.18.1 migrations
- **Background Jobs:** APScheduler 3.11.2 (–±–µ–∑ Redis, persistent –≤ PostgreSQL)
- **AI:** OpenAI API (GPT-4 –¥–ª—è NLU/responses, Whisper –¥–ª—è ASR)
- **Templates:** Jinja2 (–≤—Å—Ç—Ä–æ–µ–Ω –≤ Flask)
- **Styling:** Tailwind CSS via CDN (–±–µ–∑ build process)
- **Language:** Python 3.11+ (simple syntax, AI-friendly)

**Database Schema (Core Tables ‚Äî SQLAlchemy Models):**

```python
# models/project.py
class Project:
    id, name, description, status, created_at, updated_at

# models/feature.py
class Feature:
    id, project_id, name, description, status, status_reason,
    assigned_teams, assigned_po, release_id, created_at, updated_at

# models/release.py
class Release:
    id, project_id, version, target_date, status, created_at

# models/dependency.py
class Dependency:
    id, blocker_feature_id, blocked_feature_id, created_at

# models/meeting.py
class Meeting:
    id, project_id, title, date, participants, created_at

# models/decision.py
class Decision:
    id, meeting_id, project_id, description, created_at

# models/risk.py
class Risk:
    id, project_id, feature_id, severity, description,
    mitigation, created_at

# models/assignment.py
class Assignment:
    id, project_id, title, assignee, deadline, priority,
    source_type (leader|meeting|self), source_person_id,
    inbox_type (general|leader), reminder_times[], created_at

# models/artifact.py
class Artifact:
    id, project_id, type (report|brief|prep|minutes|research),
    title, content, content_format (json|markdown),
    rendered_html, rendered_url, render_version,
    access_token, expires_at, created_at

# models/event_log.py
class EventLog:
    id, user_id, action, entity_type, entity_id,
    timestamp, details (JSON), created_at

# models/user_context.py
class UserContext:
    user_id, active_project_id, updated_at

# models/processed_message.py
class ProcessedMessage:
    message_id (unique), processed_at
```

**Code Organization (Custom UBER_PO Starter):**

```
uber-po-bot/
‚îú‚îÄ‚îÄ app.py                      # –ì–ª–∞–≤–Ω—ã–π —Ñ–∞–π–ª ‚Äî –∑–∞–ø—É—Å–∫ –±–æ—Ç–∞
‚îú‚îÄ‚îÄ config.py                   # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–∑ .env
‚îú‚îÄ‚îÄ requirements.txt            # –°–ø–∏—Å–æ–∫ –±–∏–±–ª–∏–æ—Ç–µ–∫
‚îú‚îÄ‚îÄ .env                        # –°–µ–∫—Ä–µ—Ç—ã (–ù–ï –∫–æ–º–º–∏—Ç–∏—Ç—å!)
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ alembic/                    # –ú–∏–≥—Ä–∞—Ü–∏–∏ –ë–î
‚îÇ   ‚îú‚îÄ‚îÄ versions/
‚îÇ   ‚îî‚îÄ‚îÄ env.py
‚îú‚îÄ‚îÄ bot/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ handlers/              # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ voice.py          # –ì–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ commands.py       # /start, /help
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ callbacks.py      # –ù–∞–∂–∞—Ç–∏—è –Ω–∞ –∫–Ω–æ–ø–∫–∏
‚îÇ   ‚îú‚îÄ‚îÄ agent.py              # –†–∞–±–æ—Ç–∞ —Å GPT
‚îÇ   ‚îî‚îÄ‚îÄ prompts/              # System prompts –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤
‚îÇ       ‚îú‚îÄ‚îÄ analyst.txt
‚îÇ       ‚îú‚îÄ‚îÄ researcher.txt
‚îÇ       ‚îú‚îÄ‚îÄ pm.txt
‚îÇ       ‚îî‚îÄ‚îÄ risk_manager.txt
‚îú‚îÄ‚îÄ models/                    # –¢–∞–±–ª–∏—Ü—ã –ë–î (SQLAlchemy)
‚îÇ   ‚îú‚îÄ‚îÄ base.py
‚îÇ   ‚îú‚îÄ‚îÄ project.py
‚îÇ   ‚îú‚îÄ‚îÄ feature.py
‚îÇ   ‚îú‚îÄ‚îÄ meeting.py
‚îÇ   ‚îú‚îÄ‚îÄ assignment.py
‚îÇ   ‚îú‚îÄ‚îÄ artifact.py
‚îÇ   ‚îî‚îÄ‚îÄ event_log.py          # Audit trail
‚îú‚îÄ‚îÄ services/                  # –ë–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫–∞
‚îÇ   ‚îú‚îÄ‚îÄ radar.py              # Radar —Å–∫–æ—Ä–∏–Ω–≥ (Python —Ñ—É–Ω–∫—Ü–∏–∏)
‚îÇ   ‚îú‚îÄ‚îÄ context.py            # –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
‚îÇ   ‚îî‚îÄ‚îÄ html_render.py        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è HTML
‚îú‚îÄ‚îÄ templates/                 # HTML —à–∞–±–ª–æ–Ω—ã (Jinja2)
‚îÇ   ‚îú‚îÄ‚îÄ base.html
‚îÇ   ‚îú‚îÄ‚îÄ radar_report.html
‚îÇ   ‚îú‚îÄ‚îÄ meeting_prep.html
‚îÇ   ‚îî‚îÄ‚îÄ research_onepager.html
‚îú‚îÄ‚îÄ static/                    # –°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∞–π–ª—ã
‚îÇ   ‚îî‚îÄ‚îÄ artifacts/            # –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ HTML (–ª–æ–∫–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ)
‚îî‚îÄ‚îÄ jobs/                      # –§–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏
    ‚îú‚îÄ‚îÄ reminders.py          # –ù–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è
    ‚îî‚îÄ‚îÄ scheduler.py          # APScheduler setup
```

**Initialization Command (–¥–ª—è Epic 1 Story 1):**

```bash
# –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞
mkdir uber-po-bot
cd uber-po-bot

# Virtual environment
python3 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Dependencies
pip install python-telegram-bot==22.6 flask==3.0 sqlalchemy==2.0 \
    alembic==1.18.1 apscheduler==3.11.2 openai jinja2 python-dotenv psycopg2-binary

# –°–æ–∑–¥–∞–Ω–∏–µ .env —Ñ–∞–π–ª–∞
cat > .env << EOF
TELEGRAM_TOKEN=your_bot_token_here
OPENAI_API_KEY=your_openai_key_here
DATABASE_URL=postgresql://localhost/uber_po
YOUR_TELEGRAM_ID=your_telegram_id_here
ENVIRONMENT=development
EOF

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Alembic –¥–ª—è –º–∏–≥—Ä–∞—Ü–∏–π
alembic init alembic

# –°–æ–∑–¥–∞–Ω–∏–µ requirements.txt
pip freeze > requirements.txt
```

**Technology Versions (Verified 2026-01-29):**
- Python: 3.11+
- Flask: 3.0
- python-telegram-bot: 22.6
- SQLAlchemy: 2.0
- Alembic: 1.18.1
- APScheduler: 3.11.2
- OpenAI: latest
- PostgreSQL: 14+ (Railway managed)

**Infrastructure Decisions:**

- **PostgreSQL Schema:** Relational tables (strict structure) —Å —è–≤–Ω—ã–º–∏ —Å–≤—è–∑—è–º–∏ —á–µ—Ä–µ–∑ foreign keys
  - Projects ‚Üî Features ‚Üî Releases
  - Features ‚Üî Dependencies (blocker/blocked)
  - Meetings ‚Üî Decisions ‚Üî Risks ‚Üî Assignments
  - Artifacts ‚Üî Projects
  - EventLog (append-only audit trail)
  - UserContext (–∞–∫—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–µ–∫—Ç)
  - ProcessedMessage (idempotency check)

- **Idempotency:** –ö–∞–∂–¥–æ–µ Telegram message –∏–º–µ–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π message_id
  - –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ ingestion_id
  - Check before processing: `if message_id in processed_messages: skip`
  - –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –ø—Ä–∏ retry

- **Context Resolver:** –ê–∫—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–µ–∫—Ç —Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ user_context table
  - –ö–∞–∂–¥—ã–π –æ—Ç–≤–µ—Ç –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å: `–ö–æ–Ω—Ç–µ–∫—Å—Ç: –ü—Ä–æ–µ–∫—Ç X`
  - –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ: "–ü–µ—Ä–µ–∫–ª—é—á–∏—Å—å –Ω–∞ –ø—Ä–æ–µ–∫—Ç Y"
  - –ü—Ä–∏ –Ω–µ–æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ—Å—Ç–∏: Top-3 –≤–∞—Ä–∏–∞–Ω—Ç–∞ —Å inline-–∫–Ω–æ–ø–∫–∞–º–∏

- **Bot Communication Modes:**
  - Dev: Polling (no ngrok needed, –ø—Ä–æ—Å—Ç–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å)
  - Prod: Webhook (Railway –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Å—Ç—Ä–æ–∏—Ç HTTPS)
  - Config switch –≤ .env: `ENVIRONMENT=development|production`

- **Authentication Check (–≤—Å–µ handlers):**
```python
ALLOWED_USER_ID = int(os.getenv('YOUR_TELEGRAM_ID'))

def is_authorized(update):
    return update.message.from_user.id == ALLOWED_USER_ID
```

- **GPT Integration (bot/agent.py):**
```python
def call_gpt(prompt_file, user_message):
    system_prompt = load_prompt(prompt_file)  # prompts/analyst.txt
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_message}
        ]
    )
    return response.choices[0].message.content
```

- **APScheduler Setup (jobs/scheduler.py):**
```python
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.jobstores.sqlalchemy import SQLAlchemyJobStore

jobstores = {
    'default': SQLAlchemyJobStore(url=DATABASE_URL)
}
scheduler = BackgroundScheduler(jobstores=jobstores)

# Reminder check every minute
scheduler.add_job(check_reminders, 'interval', minutes=1)

# Morning Radar every day at 8 AM
scheduler.add_job(send_morning_radar, 'cron', hour=8)
```

- **Error Handling Strategy:**
  - All OpenAI calls wrapped –≤ try/except
  - Retry logic –¥–ª—è transient errors (3 retries, exponential backoff)
  - User-friendly error messages –≤ Telegram
  - Logging –≤—Å–µ—Ö errors

**Deployment –Ω–∞ Railway (Epic 4 Final Step):**

1. Push –∫–æ–¥ –≤ GitHub
2. –ü–æ–¥–∫–ª—é—á–∏—Ç—å Railway –∫ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—é
3. Railway –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞—ë—Ç PostgreSQL (DATABASE_URL)
4. –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç environment variables:
   - TELEGRAM_TOKEN
   - OPENAI_API_KEY
   - YOUR_TELEGRAM_ID
   - ENVIRONMENT=production
5. –ó–∞–ø—É—Å–∫–∞–µ—Ç –±–æ—Ç–∞ 24/7 (free tier: 500 hours/month)

**Logging & Monitoring (MVP):**
- Python logging module (stdout) ‚Äî Railway captures logs
- EventLog —Ç–∞–±–ª–∏—Ü–∞ –≤ PostgreSQL (audit trail)
- Print statements –¥–ª—è debugging
- Deferred: Datadog, Sentry (post-MVP)

**Development Workflow (AI-assisted, 2 weeks = 4 sprints):**

**Sprint 0 (Day 1): –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è**
- Claude —Å–æ–∑–¥–∞—ë—Ç –±–∞–∑–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞ (–ø–∞–ø–∫–∏, —Ñ–∞–π–ª—ã)
- –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –≤—Å–µ –∫–æ–Ω—Ñ–∏–≥–∏ (.env, requirements.txt, alembic)
- –°–æ–∑–¥–∞—ë—Ç –ø–µ—Ä–≤—ã–µ –º–æ–¥–µ–ª–∏ –ë–î (Project, Feature, Meeting, Assignment, Artifact, EventLog, UserContext, ProcessedMessage)
- Artem: –∑–∞–ø—É—Å–∫–∞–µ—Ç, –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —á—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç (`python app.py`)

**Sprint 1 (Days 2-4): Voice + Basic Commands**
- Claude –ø–∏—à–µ—Ç –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –≥–æ–ª–æ—Å–∞ (bot/handlers/voice.py)
- –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç Whisper API (ASR)
- –°–æ–∑–¥–∞—ë—Ç –±–∞–∑–æ–≤—ã–µ –∫–æ–º–∞–Ω–¥—ã (/start, "–°–æ–∑–¥–∞–π –ø—Ä–æ–µ–∫—Ç", "–°–æ–∑–¥–∞–π —Ñ–∏—á—É")
- –î–æ–±–∞–≤–ª—è–µ—Ç authentication check (is_authorized)
- Artem: —Ç–µ—Å—Ç–∏—Ä—É–µ—Ç –≥–æ–ª–æ—Å–æ–º, –≥–æ–≤–æ—Ä–∏—Ç —á—Ç–æ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç

**Sprint 2 (Days 5-8): Radar + Context**
- Claude –ø–∏—à–µ—Ç Radar —Å–∫–æ—Ä–∏–Ω–≥ (services/radar.py ‚Äî Python —Ñ—É–Ω–∫—Ü–∏–∏)
- –†–µ–∞–ª–∏–∑—É–µ—Ç Context Resolver (services/context.py)
- –î–æ–±–∞–≤–ª—è–µ—Ç inline –∫–Ω–æ–ø–∫–∏ (InlineKeyboardMarkup)
- –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç GPT-4 —Å system prompts (bot/agent.py)
- Artem: –ø—Ä–æ–≤–µ—Ä—è–µ—Ç "–ß—Ç–æ –≥–æ—Ä–∏—Ç?", —Ç–µ—Å—Ç–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç, –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–æ–≤

**Sprint 3 (Days 9-12): HTML + Jobs**
- Claude —Å–æ–∑–¥–∞—ë—Ç HTML —à–∞–±–ª–æ–Ω—ã (templates/*.html, Jinja2 + Tailwind CSS CDN)
- –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç APScheduler (jobs/scheduler.py, jobs/reminders.py)
- –î–æ–±–∞–≤–ª—è–µ—Ç —Ñ–æ–Ω–æ–≤—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è (GPT web search ‚Üí one-pager)
- –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç HTML artifacts (/static/artifacts/, –ø—Ä–∏–≤–∞—Ç–Ω—ã–µ —Å—Å—ã–ª–∫–∏)
- Artem: –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –ª–µ–Ω–¥–∏–Ω–≥–∏ –¥–ª—è CEO, —Ç–µ—Å—Ç–∏—Ä—É–µ—Ç –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è

**Sprint 4 (Days 13-14): Polish + Deploy**
- Claude –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç –±–∞–≥–∏ (–Ω–∞ –æ—Å–Ω–æ–≤–µ —Ñ–∏–¥–±–µ–∫–∞ Artem)
- –£–ª—É—á—à–∞–µ—Ç UI/UX (inline –∫–Ω–æ–ø–∫–∏, —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç–≤–µ—Ç–æ–≤)
- –î–µ–ø–ª–æ–∏—Ç –Ω–∞ Railway (GitHub push ‚Üí Railway auto-deploy)
- –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç environment variables –≤ Railway
- Artem: —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ prod

**–í–∞—à–∞ —Ä–æ–ª—å (Artem):** –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å ‚Üí –ì–æ–≤–æ—Ä–∏—Ç—å —á—Ç–æ –Ω–µ —Ç–∞–∫ ‚Üí Claude –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç ‚Üí –ü–æ–≤—Ç–æ—Ä–∏—Ç—å

**Claude —Ä–æ–ª—å:** –ü–∏—Å–∞—Ç—å –≤–µ—Å—å –∫–æ–¥ ‚Üí –û–±—ä—è—Å–Ω—è—Ç—å –∫–∞–∫ –∑–∞–ø—É—Å—Ç–∏—Ç—å ‚Üí –ò—Å–ø—Ä–∞–≤–ª—è—Ç—å –±–∞–≥–∏ ‚Üí –î–µ–ø–ª–æ–∏—Ç—å

**NFR Adjustments –¥–ª—è 2-week MVP:**

**Performance (—Ä–µ–ª–∞–∫—Å–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è MVP):**
- API response < 500ms –¥–ª—è 95th percentile (–≤–º–µ—Å—Ç–æ 200ms) ‚Äî acceptable –¥–ª—è single user
- Whisper API < 3 —Å–µ–∫ (–≤–º–µ—Å—Ç–æ 2 —Å–µ–∫) ‚Äî –∑–∞–≤–∏—Å–∏—Ç –æ—Ç OpenAI, –Ω–æ acceptable
- Radar generation < 10 —Å–µ–∫ –¥–ª—è 20 –ø—Ä–æ–µ–∫—Ç–æ–≤ (–≤–º–µ—Å—Ç–æ 5 —Å–µ–∫) ‚Äî SQL queries –±—ã—Å—Ç—Ä—ã–µ

**Reliability (—É–ø—Ä–æ—â—ë–Ω–Ω–æ –¥–ª—è MVP):**
- ‚úÖ Idempotency —á–µ—Ä–µ–∑ ingestion_id (–∫—Ä–∏—Ç–∏—á–Ω–æ ‚Äî –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã)
- ‚úÖ EventLog append-only (–ø—Ä–æ—Å—Ç–∞—è —Ç–∞–±–ª–∏—Ü–∞ –≤ PostgreSQL)
- ‚ö†Ô∏è Uptime: "best effort" (–Ω–µ 99.5%, –Ω–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –ª–∏—á–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)

**Security & Privacy (–º–∏–Ω–∏–º–∞–ª—å–Ω–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–µ):**
- ‚úÖ Hardcoded Telegram ID (—Ç–æ–ª—å–∫–æ Artem –∏–º–µ–µ—Ç –¥–æ—Å—Ç—É–ø)
- ‚úÖ Voice —Ñ–∞–π–ª—ã –Ω–µ —Ö—Ä–∞–Ω—è—Ç—Å—è –ø–æ—Å–ª–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ (—ç–∫–æ–Ω–æ–º–∏—è –º–µ—Å—Ç–∞ + privacy)
- ‚úÖ HTTPS –¥–ª—è webhook (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è Telegram, Railway –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
- ‚úÖ `.env` –¥–ª—è —Å–µ–∫—Ä–µ—Ç–æ–≤ (–Ω–µ –≤ git!)
- ‚ùå Encryption at rest: Skip for MVP
- ‚ùå GDPR compliance: Skip for MVP (–º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø–æ–∑–∂–µ)

**Scalability (–Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è MVP):**
- Single user ‚Äî –Ω–µ—Ç –ø—Ä–æ–±–ª–µ–º —Å –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º
- PostgreSQL —Å–ø—Ä–∞–≤–∏—Ç—Å—è —Å 10k-100k –∑–∞–ø–∏—Å–µ–π –±–µ–∑ –ø—Ä–æ–±–ª–µ–º
- –ú–æ–∂–Ω–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å –ø–æ–∑–∂–µ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏

**Observability (–º–∏–Ω–∏–º–∞–ª—å–Ω–æ):**
- ‚úÖ Python logging module (stdout) ‚Äî Railway captures logs
- ‚úÖ Print statements –¥–ª—è debugging
- ‚úÖ EventLog —Ç–∞–±–ª–∏—Ü–∞ –≤ PostgreSQL (audit trail)
- ‚ùå Distributed tracing: Skip for MVP (overkill)
- ‚ùå Datadog/Sentry: Skip for MVP (–¥–æ—Ä–æ–≥–æ)

**Accessibility:**
- ‚úÖ Text fallback –¥–ª—è voice commands (–≤—Å–µ –∫–æ–º–∞–Ω–¥—ã –¥–æ—Å—Ç—É–ø–Ω—ã —á–µ—Ä–µ–∑ —Ç–µ–∫—Å—Ç)
- ‚úÖ WCAG 2.1 AA –¥–ª—è HTML artifacts (screen reader support)

**Data Residency:**
- ‚ùå Skip for MVP (–º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø–æ–∑–∂–µ)

**Implementation Sequence (Priority Order –∏–∑ Architecture):**

1. **Sprint 0 (Day 1):** Setup project structure, database models, Alembic migrations
2. **Sprint 1 (Days 2-4):** Voice handler, Whisper integration, basic commands, authentication check
3. **Sprint 2 (Days 5-8):** Radar scoring, context resolver, inline buttons, GPT integration with prompts
4. **Sprint 3 (Days 9-12):** HTML renderer, templates, APScheduler setup, reminders, background research
5. **Sprint 4 (Days 13-14):** Bug fixes, UI polish, Railway deployment, final testing

**Cross-Component Dependencies (–∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è –ø–æ—Ä—è–¥–∫–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏):**

- **Database Models** ‚Üí All features depend on schema
- **Authentication** ‚Üí All handlers require auth check first
- **Context Resolver** ‚Üí Radar, Commands rely on active project context
- **EventLog** ‚Üí All mutations must log to audit trail
- **GPT Integration** ‚Üí Agent calls, Researcher, Analyst depend on prompt loading
- **APScheduler** ‚Üí Reminders, Morning Radar depend on scheduler init

**–ò–∑ UX Design:**

**Voice-first —Å inline-–∫–Ω–æ–ø–∫–∞–º–∏:**
- 90% –≤–≤–æ–¥ –≥–æ–ª–æ—Å–æ–º, 10% —Ç–µ–∫—Å—Ç
- –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π output —Å inline-–∫–Ω–æ–ø–∫–∞–º–∏ Telegram
- Quick actions: [‚úÖ –ü–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å] [‚ùå –û—Ç–º–µ–Ω–∏—Ç—å] [üìä –ü–æ–¥—Ä–æ–±–Ω–µ–µ] [‚ùì –ü–æ—á–µ–º—É?]
- –ù–∏–∫–∞–∫–∏—Ö —Ñ–æ—Ä–º —Å –ø–æ–ª—è–º–∏ ‚Äî —Ç–æ–ª—å–∫–æ –≥–æ–ª–æ—Å + –∫–Ω–æ–ø–∫–∏ –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è

**–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –≤–∏–¥–∏–º–æ—Å—Ç—å:**
- –ö–∞–∂–¥—ã–π –æ—Ç–≤–µ—Ç –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å `–ö–æ–Ω—Ç–µ–∫—Å—Ç: –ü—Ä–æ–µ–∫—Ç X` –∏–ª–∏ `–ö–æ–Ω—Ç–µ–∫—Å—Ç: –í—Å–µ –ø—Ä–æ–µ–∫—Ç—ã`
- –Ø–≤–Ω—ã–π –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞/—Ä–µ–∂–∏–º–∞ –≤ –∫–∞–∂–¥–æ–º –æ—Ç–≤–µ—Ç–µ
- –†–µ–∂–∏–º –∞–≥–µ–Ω—Ç–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è: `–†–µ–∂–∏–º: –ê–≥–µ–Ω—Ç Researcher`

**–ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –æ—Ç–≤–µ—Ç–æ–≤:**
- Radar (—É—Ç—Ä–æ –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫–∞): 30 —Å–µ–∫—É–Ω–¥ ‚Üí Top-3 –∫—Ä–∞—Ç–∫–æ
- Meeting Prep (–∑–∞ 10 –º–∏–Ω—É—Ç –¥–æ –≤—Å—Ç—Ä–µ—á–∏): 2-3 –º–∏–Ω—É—Ç—ã ‚Üí —Å—Ç–∞—Ç—É—Å + –≤–æ–ø—Ä–æ—Å—ã + —Ä–∏—Å–∫–∏
- Research "–Ω–µ —Ç—Ä–µ–≤–æ–∂—å –º–µ–Ω—è": 15-30 –º–∏–Ω—É—Ç –≤ —Ñ–æ–Ω–µ ‚Üí structured one-pager

**HTML –ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã (–∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è CEO –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–π!):**
- Jinja2 templates: `radar_report.html`, `research_onepager.html`, `meeting_prep.html`, `project_brief.html`
- Tailwind CSS –¥–ª—è –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –≤–∏–¥–∞
- –ü—Ä–∏–≤–∞—Ç–Ω—ã–µ —Å—Å—ã–ª–∫–∏ `/artifacts/{random_token}` —Å TTL=7 –¥–Ω–µ–π
- Responsive design (Tailwind responsive classes)
- WCAG 2.1 AA compliant –¥–ª—è accessibility

**–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è:**
- "–°–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ —á–µ—Ä–µ–∑ –∫–æ–Ω—Ç—Ä–æ–ª—å" ‚Üí Radar Trust ‚â• 80% (–¥–æ–ª—è items, –≥–¥–µ explainability –ø—Ä–∏–∑–Ω–∞–Ω–∞ –ø–æ–ª–µ–∑–Ω–æ–π)
- "–î–æ–≤–µ—Ä–∏–µ" ‚Üí Command Success Rate ‚â• 85% (–≥–æ–ª–æ—Å‚Üí–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ –±–µ–∑ —Ä–µ–º–æ–Ω—Ç–∞)
- "–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª–∏–∑–º" ‚Üí –∫—Ä–∞—Å–∏–≤—ã–µ HTML –ª–µ–Ω–¥–∏–Ω–≥–∏ –¥–ª—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏ –∏–¥–µ–π —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤—É
- "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å" ‚Üí —ç–∫–æ–Ω–æ–º–∏—è 30-60 –º–∏–Ω—É—Ç –≤ –¥–µ–Ω—å

**Repair/Undo:**
- "–û—Ç–º–µ–Ω–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–µ" –¥–æ–ª–∂–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å (–æ—Ç–∫–∞—Ç –ø–æ—Å–ª–µ–¥–Ω–µ–π –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å –∞—É–¥–∏—Ç–æ–º)
- "–ù–µ—Ç, —è –∏–º–µ–ª –≤ –≤–∏–¥—É –ø—Ä–æ–µ–∫—Ç X, –∞ –Ω–µ Z" ‚Üí –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
- Repair/Undo Rate ‚â§ 15% (–¥–æ–ª—è –∫–æ–º–∞–Ω–¥, —Ç—Ä–µ–±—É—é—â–∏—Ö –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è)

**System Prompts –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤:**
- `prompts/orchestrator.txt`: –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è, workflow-—à–∞–≥–∏, handoff, QC
- `prompts/analyst.txt`: –±—Ä–∏—Ñ—ã/—Å—Ç—Ä—É–∫—Ç—É—Ä—ã/—Å–ø—Ä–∞–≤–∫–∏ v1, —É—Ç–æ—á–Ω–µ–Ω–∏—è
- `prompts/pm.txt`: PRD-lite, user stories, AC
- `prompts/researcher.txt`: "–Ω–µ —Ç—Ä–µ–≤–æ–∂—å", one-pager, –∏—Å—Ç–æ—á–Ω–∏–∫–∏/–¥–æ–ø—É—â–µ–Ω–∏—è
- `prompts/meeting_secretary.txt`: minutes ‚Üí decisions/actions/risks/changes
- `prompts/risk_manager.txt`: "–≥–¥–µ —Ä–∏—Å–∫/—á—Ç–æ –≥–æ—Ä–∏—Ç" + –ø—Ä–∏—á–∏–Ω—ã
- `prompts/release_manager.txt`: —Ä–µ–ª–∏–∑—ã/–ø–µ—Ä–µ–Ω–æ—Å—ã/—Å–æ—Å—Ç–∞–≤
- `prompts/reviewer.txt`: —á–µ–∫–ª–∏—Å—Ç—ã –ø–æ–ª–Ω–æ—Ç—ã/—Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏/—Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã R9
- –ó–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–º–∞–Ω–¥—ã/workflow

### FR Coverage Map

| FR | Epic | Description |
|----|------|-------------|
| FR-001 | Epic 1 | –ü—Ä–æ–µ–∫—Ç—ã –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ ‚Äî –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ |
| FR-002 | Epic 1 | Inbox –∏–¥–µ–π ‚Äî –≥–æ–ª–æ—Å–æ–≤–∞—è —Ñ–∏–∫—Å–∞—Ü–∏—è |
| FR-003 | Epic 1 | –§–∏—á–∏ ‚Äî —Å–æ–∑–¥–∞–Ω–∏–µ, —Å—Ç–∞—Ç—É—Å—ã –≥–æ–ª–æ—Å–æ–º |
| FR-004 | Epic 2 | Dependency tracking ‚Üí –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –≤–ª–∏—è—é—Ç –Ω–∞ Radar |
| FR-005 | Epic 1 | –†–µ–ª–∏–∑—ã ‚Äî —Å–æ–∑–¥–∞–Ω–∏–µ, –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ñ–∏—á |
| FR-006 | Epic 3 | –ü—Ä–æ—Ç–æ–∫–æ–ª—ã –≤—Å—Ç—Ä–µ—á ‚Üí auto-extraction |
| FR-007 | Epic 3 | –ü–æ—Ä—É—á–µ–Ω–∏—è + –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è |
| FR-008 | Epic 2 | Radar Top-3 —Å explainability |
| FR-009 | Epic 3 | Meeting Prep –∑–∞ 2 –º–∏–Ω—É—Ç—ã |
| FR-010 | Epic 3 | –°–ø—Ä–∞–≤–∫–∏ –¥–ª—è CEO (HTML) |
| FR-011 | Epic 4 | –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è "–Ω–µ —Ç—Ä–µ–≤–æ–∂—å –º–µ–Ω—è" |
| FR-012 | Epic 2, 4 | –ú—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ—Å—Ç—å (prompts + researcher) |
| FR-013 | Epic 3 | HTML Artifacts (–ª–µ–Ω–¥–∏–Ω–≥–∏ –¥–ª—è CEO) |
| FR-014 | Epic 3 | Leader Tasks Inbox |

## Epic List

### Epic 1: Voice Capture ‚Äî –ë—ã—Å—Ç—Ä–∞—è —Ñ–∏–∫—Å–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–æ–≤ –∏ –∑–∞–¥–∞—á –≥–æ–ª–æ—Å–æ–º

Artem –º–æ–∂–µ—Ç **–º–≥–Ω–æ–≤–µ–Ω–Ω–æ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å –ª—é–±—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≥–æ–ª–æ—Å–æ–º** –±–µ–∑ —Ñ–æ—Ä–º –∏ –∫–ª–∏–∫–æ–≤ ‚Äî –ø—Ä–æ–µ–∫—Ç—ã, —Ñ–∏—á–∏, –∏–¥–µ–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ –±–∞–∑—É –∑–∞ 10 —Å–µ–∫—É–Ω–¥.

**FRs covered:** FR-001, FR-002, FR-003, FR-005, NFR-002, Architecture (Database models, Authentication, Whisper, Basic commands)

**Sprint:** Sprint 0 + Sprint 1 (Days 1-4)

### Epic 2: Intelligence Radar ‚Äî –°–∏—Å—Ç–µ–º–∞ —Ä–∞–Ω–Ω–µ–≥–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è

Artem –º–æ–∂–µ—Ç **–º–≥–Ω–æ–≤–µ–Ω–Ω–æ —É–≤–∏–¥–µ—Ç—å –≤—Å–µ –ø—Ä–æ–±–ª–µ–º—ã** –≤ 20 –ø—Ä–æ–µ–∫—Ç–∞—Ö —á–µ—Ä–µ–∑ –∫–æ–º–∞–Ω–¥—É "–ß—Ç–æ –≥–æ—Ä–∏—Ç?" ‚Äî —Å–∏—Å—Ç–µ–º–∞ —Å–∞–º–∞ –Ω–∞—Ö–æ–¥–∏—Ç –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏, —Ä–∏—Å–∫–∏, –ø—Ä–æ—Å—Ä–æ—á–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏ –∏ –æ–±—ä—è—Å–Ω—è–µ—Ç –ø–æ—á–µ–º—É.

**FRs covered:** FR-004, FR-008, FR-012 (partial), Architecture (Radar scoring, Context Resolver, GPT integration), UX (Inline-–∫–Ω–æ–ø–∫–∏, explainability)

**Sprint:** Sprint 2 (Days 5-8)

### Epic 3: Workflow Automation ‚Äî –í—Å—Ç—Ä–µ—á–∏, –ø–æ—Ä—É—á–µ–Ω–∏—è, –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è CEO

Artem –º–æ–∂–µ—Ç **–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä—É—Ç–∏–Ω—É**: –Ω–∞–¥–∏–∫—Ç–æ–≤–∞—Ç—å –ø—Ä–æ—Ç–æ–∫–æ–ª –≤—Å—Ç—Ä–µ—á–∏ (—Å–∏—Å—Ç–µ–º–∞ –∏–∑–≤–ª–µ—á—ë—Ç —Ä–µ—à–µ–Ω–∏—è/–ø–æ—Ä—É—á–µ–Ω–∏—è), –ø–æ–ª—É—á–∏—Ç—å –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è –æ –¥–µ–¥–ª–∞–π–Ω–∞—Ö, –∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫—Ä–∞—Å–∏–≤—ã–π HTML-–ª–µ–Ω–¥–∏–Ω–≥ –¥–ª—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏ CEO.

**FRs covered:** FR-006, FR-007, FR-009, FR-010, FR-013, FR-014, Architecture (APScheduler, HTML rendering)

**Sprint:** Sprint 3 (Days 9-12)

### Epic 4: Autonomous Research ‚Äî –î–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π + Production

Artem –º–æ–∂–µ—Ç **–¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞—Ç—å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è** —Å–∏—Å—Ç–µ–º–µ ("–ù–µ —Ç—Ä–µ–≤–æ–∂—å –º–µ–Ω—è") –∏ –ø–æ–ª—É—á–∏—Ç—å –≥–æ—Ç–æ–≤—ã–π one-pager —É—Ç—Ä–æ–º, –∞ —Ç–∞–∫–∂–µ –∏–º–µ—Ç—å **—Ä–∞–±–æ—Ç–∞—é—â–∏–π 24/7 –±–æ—Ç** –Ω–∞ Railway.

**FRs covered:** FR-011, FR-012 (full), NFR-001, NFR-002, NFR-003, Architecture (Railway deployment, Webhook mode, Background research)

**Sprint:** Sprint 3 (partial) + Sprint 4 (Days 9-14)

---

## Epic 1: Voice Capture ‚Äî –ë—ã—Å—Ç—Ä–∞—è —Ñ–∏–∫—Å–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–æ–≤ –∏ –∑–∞–¥–∞—á –≥–æ–ª–æ—Å–æ–º

**Goal:** Artem –º–æ–∂–µ—Ç –º–≥–Ω–æ–≤–µ–Ω–Ω–æ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å –ª—é–±—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≥–æ–ª–æ—Å–æ–º –±–µ–∑ —Ñ–æ—Ä–º –∏ –∫–ª–∏–∫–æ–≤ ‚Äî –ø—Ä–æ–µ–∫—Ç—ã, —Ñ–∏—á–∏, –∏–¥–µ–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ –±–∞–∑—É –∑–∞ 10 —Å–µ–∫—É–Ω–¥.

### Story 1.1: Project Initialization & Setup

As a developer,
I want to initialize the UBER_PO bot project structure with all required dependencies,
So that I have a working foundation ready for development.

**Acceptance Criteria:**

**Given** I have Python 3.11+ installed
**When** I run the initialization commands
**Then** the project structure is created with all folders (bot/, models/, services/, templates/, static/, jobs/)
**And** all dependencies are installed (python-telegram-bot==22.6, flask==3.0, sqlalchemy==2.0, alembic==1.18.1, apscheduler==3.11.2, openai, jinja2, python-dotenv, psycopg2-binary)
**And** .env file is created with placeholders for TELEGRAM_TOKEN, OPENAI_API_KEY, DATABASE_URL, YOUR_TELEGRAM_ID, ENVIRONMENT
**And** .gitignore is configured to exclude .env, venv/, __pycache__/, *.pyc
**And** requirements.txt contains all pinned versions
**And** README.md has setup instructions

**Given** the project structure is initialized
**When** I run `python app.py`
**Then** the application starts without errors
**And** I see "Bot initialization successful" in logs

### Story 1.2: Database Foundation ‚Äî Core Models

As a developer,
I want to create the core database models for Projects, Features, and audit logging,
So that I can store user data with proper structure and relationships.

**Acceptance Criteria:**

**Given** SQLAlchemy and Alembic are installed
**When** I create models/base.py with Base declarative class
**Then** all models inherit from Base

**Given** Base class exists
**When** I create models/project.py
**Then** Project model has fields: id (PK), name (String 200, unique), description (Text, nullable), status (String 50, default='active'), created_at (DateTime), updated_at (DateTime)

**Given** Project model exists
**When** I create models/feature.py
**Then** Feature model has fields: id (PK), project_id (FK to Project), name (String 200), description (Text, nullable), status (String 50, default='backlog'), status_reason (Text, nullable), assigned_teams (Text, nullable), assigned_po (String 100, nullable), release_id (FK to Release, nullable), created_at, updated_at
**And** Feature has relationship to Project (many-to-one)

**Given** Base models are created
**When** I create models/event_log.py
**Then** EventLog model has fields: id (PK), user_id (String 100), action (String 100), entity_type (String 50), entity_id (Integer), timestamp (DateTime, default=now), details (JSON), created_at
**And** EventLog is append-only (no update/delete methods)

**Given** Base models are created
**When** I create models/user_context.py
**Then** UserContext model has fields: user_id (String 100, PK), active_project_id (FK to Project, nullable), updated_at
**And** UserContext has relationship to Project

**Given** Base models are created
**When** I create models/processed_message.py
**Then** ProcessedMessage model has fields: message_id (String 100, PK, unique), processed_at (DateTime, default=now)

**Given** all models are created
**When** I run `alembic revision --autogenerate -m "initial schema"`
**Then** migration file is generated in alembic/versions/
**And** migration includes create_table for Project, Feature, EventLog, UserContext, ProcessedMessage

**Given** migration is generated
**When** I run `alembic upgrade head`
**Then** all tables are created in PostgreSQL
**And** I can query tables using psql or SQLAlchemy session

### Story 1.3: Telegram Bot Integration & Authentication

As Artem,
I want the bot to authenticate only my Telegram ID and respond to /start command,
So that only I can use the bot.

**Acceptance Criteria:**

**Given** python-telegram-bot is installed
**When** I create bot/handlers/commands.py with /start handler
**Then** handler function `start_command(update, context)` exists

**Given** .env has YOUR_TELEGRAM_ID set
**When** I create authentication check function `is_authorized(update)` in bot/handlers/commands.py
**Then** function returns True if update.message.from_user.id == int(os.getenv('YOUR_TELEGRAM_ID'))
**And** function returns False otherwise

**Given** /start handler exists
**When** an unauthorized user sends /start
**Then** bot responds with "–ò–∑–≤–∏–Ω–∏—Ç–µ, –¥–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â—ë–Ω." (Access denied)
**And** no further processing occurs

**Given** /start handler and auth check exist
**When** I (authorized user) send /start to the bot
**Then** bot responds with welcome message: "–ü—Ä–∏–≤–µ—Ç, Artem! üëã UBER_PO –±–æ—Ç –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ. –û—Ç–ø—Ä–∞–≤—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–ª–∏ –∫–æ–º–∞–Ω–¥—É."
**And** EventLog records: user_id=my_telegram_id, action='bot_started', entity_type='user', timestamp=now

**Given** app.py exists
**When** I configure bot in polling mode (ENVIRONMENT=development in .env)
**Then** app.py initializes bot with `Application.builder().token(TELEGRAM_TOKEN).build()`
**And** app.py adds /start handler
**And** app.py starts polling with `application.run_polling()`

**Given** bot is running in polling mode
**When** I send /start from Telegram
**Then** I receive welcome message within 2 seconds
**And** bot logs "Received /start command from user {telegram_id}"

### Story 1.4: Voice Recognition with Whisper API

As Artem,
I want to send voice messages to the bot and receive transcriptions,
So that I can interact with the system using voice instead of typing.

**Acceptance Criteria:**

**Given** OpenAI library is installed and OPENAI_API_KEY is set in .env
**When** I create bot/handlers/voice.py with voice message handler
**Then** handler function `handle_voice(update, context)` exists

**Given** voice handler exists
**When** unauthorized user sends voice message
**Then** bot responds with "–ò–∑–≤–∏–Ω–∏—Ç–µ, –¥–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â—ë–Ω."
**And** no voice processing occurs

**Given** voice handler exists and user is authorized
**When** I send a voice message to the bot
**Then** bot downloads voice file from Telegram using `update.message.voice.get_file()`
**And** bot saves voice file temporarily to `/tmp/{message_id}.ogg`

**Given** voice file is downloaded
**When** bot calls Whisper API
**Then** bot opens voice file and calls `openai.Audio.transcribe(model="whisper-1", file=audio_file, language="ru")`
**And** bot receives transcript text

**Given** transcript is received
**When** processing completes
**Then** bot deletes temporary voice file from `/tmp/`
**And** voice file is NOT stored permanently

**Given** transcript text exists
**When** transcription is successful
**Then** bot responds to user with: "üé§ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {transcript_text}"
**And** EventLog records: user_id, action='voice_transcribed', entity_type='message', entity_id=message_id, details={'transcript': transcript_text, 'duration': voice_duration}

**Given** voice handler is implemented
**When** I send 5-second voice message "–°–æ–∑–¥–∞–π –ø—Ä–æ–µ–∫—Ç Mobile App"
**Then** bot responds within 3 seconds with transcription
**And** transcript accuracy is at least 90% for clear Russian speech

**Given** Whisper API call fails (network error, API down)
**When** bot attempts transcription
**Then** bot retries up to 3 times with exponential backoff (1s, 2s, 4s)
**And** if all retries fail, bot responds: "–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –≥–æ–ª–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑ –∏–ª–∏ –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–º."
**And** EventLog records error details

**Given** voice handler is complete
**When** I check ProcessedMessage table after voice processing
**Then** message_id is recorded to prevent duplicate processing
**And** if same message_id is received again (retry), bot responds immediately without reprocessing

### Story 1.5: Create Project Command via Voice

As Artem,
I want to say "–°–æ–∑–¥–∞–π –ø—Ä–æ–µ–∫—Ç Mobile App" and have the project created in the database,
So that I can quickly capture project information without forms.

**Acceptance Criteria:**

**Given** voice transcription works
**When** I create NLU function `parse_command(transcript)` in bot/handlers/voice.py
**Then** function identifies command type (create_project, create_feature, create_idea, etc.)
**And** function extracts entities (project_name, feature_name, etc.)

**Given** NLU parser exists
**When** transcript is "–°–æ–∑–¥–∞–π –ø—Ä–æ–µ–∫—Ç Mobile App"
**Then** parser returns {'command': 'create_project', 'project_name': 'Mobile App'}

**Given** NLU identifies create_project command
**When** I create `handle_create_project(project_name, user_id)` in bot/handlers/commands.py
**Then** function creates new Project in database with name=project_name, status='active'
**And** function creates EventLog entry: action='project_created', entity_type='project', entity_id=new_project_id, details={'name': project_name}

**Given** project creation handler exists
**When** I say "–°–æ–∑–¥–∞–π –ø—Ä–æ–µ–∫—Ç Mobile App"
**Then** new Project is inserted into database
**And** bot responds: "‚úÖ –ü—Ä–æ–µ–∫—Ç 'Mobile App' —Å–æ–∑–¥–∞–Ω! ID: {project_id}"
**And** EventLog contains project_created entry

**Given** project is created
**When** I create UserContext logic
**Then** newly created project is automatically set as active_project_id in UserContext for this user
**And** bot response includes: "–ö–æ–Ω—Ç–µ–∫—Å—Ç: –ü—Ä–æ–µ–∫—Ç Mobile App"

**Given** project creation works
**When** I try to create project with same name "–°–æ–∑–¥–∞–π –ø—Ä–æ–µ–∫—Ç Mobile App" again
**Then** bot responds: "‚ö†Ô∏è –ü—Ä–æ–µ–∫—Ç 'Mobile App' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç. ID: {existing_project_id}"
**And** no duplicate project is created

**Given** transcript is ambiguous (e.g., "–°–æ–∑–¥–∞–π –ø—Ä–æ–µ–∫—Ç")
**When** NLU parser cannot extract project_name
**Then** bot responds: "‚ùì –ö–∞–∫ –Ω–∞–∑–≤–∞—Ç—å –ø—Ä–æ–µ–∫—Ç? –°–∫–∞–∂–∏—Ç–µ: '–°–æ–∑–¥–∞–π –ø—Ä–æ–µ–∫—Ç [–Ω–∞–∑–≤–∞–Ω–∏–µ]'"
**And** no project is created

**Given** multiple projects exist
**When** I check UserContext after creating a new project
**Then** active_project_id points to the newly created project
**And** all subsequent commands use this context

### Story 1.6: Feature Management via Voice

As Artem,
I want to create features and update their status via voice commands,
So that I can track work without manual data entry.

**Acceptance Criteria:**

**Given** NLU parser exists
**When** transcript is "–°–æ–∑–¥–∞–π —Ñ–∏—á—É –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏"
**Then** parser returns {'command': 'create_feature', 'feature_name': '–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏'}

**Given** NLU identifies create_feature command
**When** I create `handle_create_feature(feature_name, project_id, user_id)` in bot/handlers/commands.py
**Then** function creates Feature in database with name=feature_name, project_id=active_project_id, status='backlog'
**And** EventLog records: action='feature_created', entity_type='feature', entity_id=new_feature_id

**Given** active project context exists (UserContext.active_project_id is set)
**When** I say "–°–æ–∑–¥–∞–π —Ñ–∏—á—É –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏"
**Then** Feature is created with project_id = active_project_id
**And** bot responds: "‚úÖ –§–∏—á–∞ '–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏' —Å–æ–∑–¥–∞–Ω–∞ –≤ –ø—Ä–æ–µ–∫—Ç–µ 'Mobile App'. –°—Ç–∞—Ç—É—Å: backlog"

**Given** no active project context (UserContext.active_project_id is NULL)
**When** I say "–°–æ–∑–¥–∞–π —Ñ–∏—á—É –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏"
**Then** bot responds: "‚ùì –°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–µ–∫—Ç. –°–∫–∞–∂–∏—Ç–µ: '–ü–µ—Ä–µ–∫–ª—é—á–∏—Å—å –Ω–∞ –ø—Ä–æ–µ–∫—Ç [–Ω–∞–∑–≤–∞–Ω–∏–µ]' –∏–ª–∏ —Å–æ–∑–¥–∞–π—Ç–µ –Ω–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç."
**And** no feature is created

**Given** NLU parser exists
**When** transcript is "–§–∏—á–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –≥–æ—Ç–æ–≤–∞"
**Then** parser returns {'command': 'update_feature_status', 'feature_name': '–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏', 'new_status': '–≥–æ—Ç–æ–≤–∞'}

**Given** NLU identifies update_feature_status command
**When** I create `handle_update_feature_status(feature_name, new_status, project_id, user_id)`
**Then** function finds Feature by name in active project
**And** function updates Feature.status = map_status(new_status) where map maps '–≥–æ—Ç–æ–≤–∞' ‚Üí 'done', '–≤ —Ä–∞–±–æ—Ç–µ' ‚Üí 'in_progress', '–∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞' ‚Üí 'blocked'
**And** EventLog records: action='feature_status_updated', entity_type='feature', entity_id, details={'old_status': old, 'new_status': new, 'reason': reason if provided}

**Given** feature "–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏" exists in active project
**When** I say "–§–∏—á–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –≥–æ—Ç–æ–≤–∞"
**Then** Feature.status is updated to 'done'
**And** Feature.updated_at is set to now
**And** bot responds: "‚úÖ –°—Ç–∞—Ç—É—Å —Ñ–∏—á–∏ '–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏' –∏–∑–º–µ–Ω—ë–Ω: backlog ‚Üí done"

**Given** feature name is ambiguous (multiple matches)
**When** I say "–§–∏—á–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≥–æ—Ç–æ–≤–∞"
**Then** bot responds with Top-3 matches and inline buttons:
"‚ùì –ù–∞–π–¥–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∏—á:
[1Ô∏è‚É£ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏] [2Ô∏è‚É£ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –ø–ª–∞—Ç–µ–∂–µ–π] [3Ô∏è‚É£ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π]"
**And** I can click button to select correct feature

**Given** feature does not exist
**When** I say "–§–∏—á–∞ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è –≥–æ—Ç–æ–≤–∞"
**Then** bot responds: "‚ùå –§–∏—á–∞ '–Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –ø—Ä–æ–µ–∫—Ç–µ 'Mobile App'. –°–æ–∑–¥–∞–π—Ç–µ –µ—ë —Å–Ω–∞—á–∞–ª–∞."

### Story 1.7: Ideas Inbox ‚Äî Quick Capture

As Artem,
I want to quickly capture ideas via voice even without specifying a project,
So that no thoughts are lost.

**Acceptance Criteria:**

**Given** NLU parser exists
**When** transcript is "–ò–¥–µ—è: –¥–æ–±–∞–≤–∏—Ç—å dark mode"
**Then** parser returns {'command': 'capture_idea', 'idea_text': '–¥–æ–±–∞–≤–∏—Ç—å dark mode'}

**Given** I need to store ideas
**When** I create models/idea.py
**Then** Idea model has fields: id (PK), project_id (FK to Project, nullable), content (Text), created_at, converted_to_feature_id (FK to Feature, nullable)
**And** migration is created and applied

**Given** NLU identifies capture_idea command
**When** I create `handle_capture_idea(idea_text, project_id, user_id)` in bot/handlers/commands.py
**Then** function creates Idea in database with content=idea_text, project_id=active_project_id (if exists, else NULL)
**And** EventLog records: action='idea_captured', entity_type='idea', entity_id=new_idea_id

**Given** active project context exists
**When** I say "–ò–¥–µ—è: –¥–æ–±–∞–≤–∏—Ç—å dark mode"
**Then** Idea is created with project_id = active_project_id
**And** bot responds: "üí° –ò–¥–µ—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ –ø—Ä–æ–µ–∫—Ç–µ 'Mobile App': '–¥–æ–±–∞–≤–∏—Ç—å dark mode'"

**Given** no active project context
**When** I say "–ò–¥–µ—è: –¥–æ–±–∞–≤–∏—Ç—å dark mode"
**Then** Idea is created with project_id = NULL (inbox)
**And** bot responds: "üí° –ò–¥–µ—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ –æ–±—â–∏–π Inbox: '–¥–æ–±–∞–≤–∏—Ç—å dark mode'. –ü–æ–∑–∂–µ –º–æ–∂–Ω–æ –ø—Ä–∏–≤—è–∑–∞—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É."

**Given** idea exists
**When** I say "–ü—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å –∏–¥–µ—é dark mode –≤ —Ñ–∏—á—É"
**Then** bot finds Idea by partial match of content
**And** creates Feature with name=idea.content, project_id=active_project_id
**And** updates Idea.converted_to_feature_id = new_feature_id
**And** bot responds: "‚úÖ –ò–¥–µ—è '–¥–æ–±–∞–≤–∏—Ç—å dark mode' –ø—Ä–µ–≤—Ä–∞—â–µ–Ω–∞ –≤ —Ñ–∏—á—É –≤ –ø—Ä–æ–µ–∫—Ç–µ 'Mobile App'"

**Given** multiple ideas match query
**When** I say "–ü—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å –∏–¥–µ—é dark –≤ —Ñ–∏—á—É"
**Then** bot shows Top-3 matches with inline buttons for selection

**Given** I want to review inbox ideas
**When** I say "–ü–æ–∫–∞–∂–∏ –∏–¥–µ–∏ –≤ inbox"
**Then** bot lists all Idea entries where project_id IS NULL
**And** shows count and first 5 ideas with [–ü—Ä–∏–≤—è–∑–∞—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É] [–ü—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å –≤ —Ñ–∏—á—É] buttons

---

## Epic 2: Intelligence Radar ‚Äî –°–∏—Å—Ç–µ–º–∞ —Ä–∞–Ω–Ω–µ–≥–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è

**Goal:** Artem –º–æ–∂–µ—Ç –º–≥–Ω–æ–≤–µ–Ω–Ω–æ —É–≤–∏–¥–µ—Ç—å –≤—Å–µ –ø—Ä–æ–±–ª–µ–º—ã –≤ 20 –ø—Ä–æ–µ–∫—Ç–∞—Ö —á–µ—Ä–µ–∑ –∫–æ–º–∞–Ω–¥—É "–ß—Ç–æ –≥–æ—Ä–∏—Ç?" ‚Äî —Å–∏—Å—Ç–µ–º–∞ —Å–∞–º–∞ –Ω–∞—Ö–æ–¥–∏—Ç –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏, —Ä–∏—Å–∫–∏, –ø—Ä–æ—Å—Ä–æ—á–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏ –∏ –æ–±—ä—è—Å–Ω—è–µ—Ç –ø–æ—á–µ–º—É.

### Story 2.1: Context Management ‚Äî Project Switching

As Artem,
I want to switch between projects via voice commands and see the active context in every response,
So that I always know which project I'm working with.

**Acceptance Criteria:**

**Given** I create services/context.py with ContextResolver class
**When** ContextResolver is initialized
**Then** it can get and set active project for a user_id

**Given** ContextResolver exists
**When** I create `get_active_project(user_id)` method
**Then** method queries UserContext table for user_id
**And** returns active_project_id or None if not set

**Given** ContextResolver exists
**When** I create `set_active_project(user_id, project_id)` method
**Then** method inserts or updates UserContext with user_id and project_id
**And** sets updated_at to now

**Given** NLU parser exists
**When** transcript is "–ü–µ—Ä–µ–∫–ª—é—á–∏—Å—å –Ω–∞ –ø—Ä–æ–µ–∫—Ç Mobile App"
**Then** parser returns {'command': 'switch_project', 'project_name': 'Mobile App'}

**Given** switch_project command is identified
**When** I create `handle_switch_project(project_name, user_id)` in bot/handlers/commands.py
**Then** function searches for Project by name (case-insensitive, partial match)
**And** if found: updates UserContext.active_project_id
**And** if not found: responds with "–ü—Ä–æ–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω"
**And** if multiple matches: shows Top-3 with inline buttons

**Given** project "Mobile App" exists
**When** I say "–ü–µ—Ä–µ–∫–ª—é—á–∏—Å—å –Ω–∞ –ø—Ä–æ–µ–∫—Ç Mobile App"
**Then** UserContext.active_project_id is updated to Mobile App project_id
**And** bot responds: "‚úÖ –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–∫–ª—é—á—ë–Ω –Ω–∞ –ø—Ä–æ–µ–∫—Ç 'Mobile App'"

**Given** I create response formatting function `format_response(message, user_id)`
**When** function is called
**Then** it prepends "–ö–æ–Ω—Ç–µ–∫—Å—Ç: {active_project_name}" to message if active project exists
**And** it prepends "–ö–æ–Ω—Ç–µ–∫—Å—Ç: –í—Å–µ –ø—Ä–æ–µ–∫—Ç—ã" if active_project_id is NULL

**Given** active project is "Mobile App"
**When** bot sends any response
**Then** response starts with "–ö–æ–Ω—Ç–µ–∫—Å—Ç: –ü—Ä–æ–µ–∫—Ç Mobile App\n\n{actual_message}"

### Story 2.2: Dependency Tracking

As Artem,
I want to mark features as blocking each other,
So that Radar can identify blocked features.

**Acceptance Criteria:**

**Given** I need to track dependencies
**When** I create models/dependency.py
**Then** Dependency model has fields: id (PK), blocker_feature_id (FK to Feature), blocked_feature_id (FK to Feature), created_at
**And** migration is created and applied

**Given** NLU parser exists
**When** transcript is "–§–∏—á–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –±–ª–æ–∫–∏—Ä—É–µ—Ç —Ñ–∏—á—É –¥–∞—à–±–æ—Ä–¥ –º–µ—Ç—Ä–∏–∫"
**Then** parser returns {'command': 'create_dependency', 'blocker_name': '–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏', 'blocked_name': '–¥–∞—à–±–æ—Ä–¥ –º–µ—Ç—Ä–∏–∫'}

**Given** create_dependency command is identified
**When** I create `handle_create_dependency(blocker_name, blocked_name, project_id, user_id)`
**Then** function finds blocker Feature by name in active project
**And** function finds blocked Feature by name in active project
**And** creates Dependency with blocker_feature_id and blocked_feature_id
**And** EventLog records: action='dependency_created'

**Given** features "–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏" and "–¥–∞—à–±–æ—Ä–¥ –º–µ—Ç—Ä–∏–∫" exist
**When** I say "–§–∏—á–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –±–ª–æ–∫–∏—Ä—É–µ—Ç —Ñ–∏—á—É –¥–∞—à–±–æ—Ä–¥ –º–µ—Ç—Ä–∏–∫"
**Then** Dependency is created
**And** bot responds: "‚úÖ –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —Å–æ–∑–¥–∞–Ω–∞: '–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏' –±–ª–æ–∫–∏—Ä—É–µ—Ç '–¥–∞—à–±–æ—Ä–¥ –º–µ—Ç—Ä–∏–∫'"

**Given** dependency exists
**When** I query Feature with relationships
**Then** Feature has `blockers` (features that block this one) and `blocking` (features this one blocks) relationships

### Story 2.3: GPT Integration with System Prompts

As Artem,
I want the bot to use GPT-4 with different system prompts for different tasks,
So that responses are contextual and intelligent.

**Acceptance Criteria:**

**Given** I create bot/agent.py
**When** I create `load_prompt(prompt_file)` function
**Then** function reads file from bot/prompts/{prompt_file}.txt
**And** returns content as string

**Given** I create bot/prompts/analyst.txt
**Then** file contains system prompt: "–¢—ã –∞–Ω–∞–ª–∏—Ç–∏–∫ –ø—Ä–æ–µ–∫—Ç–æ–≤. –¢–≤–æ—è –∑–∞–¥–∞—á–∞: —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, —Å–æ–∑–¥–∞–≤–∞—Ç—å —Å–ø—Ä–∞–≤–∫–∏ –∏ –æ—Ç—á—ë—Ç—ã. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, –∏—Å–ø–æ–ª—å–∑—É–π –º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏. –í—Å–µ–≥–¥–∞ —É–∫–∞–∑—ã–≤–∞–π –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö."

**Given** I create bot/prompts/risk_manager.txt
**Then** file contains: "–¢—ã Risk Manager. –¢–≤–æ—è –∑–∞–¥–∞—á–∞: –Ω–∞—Ö–æ–¥–∏—Ç—å –ø—Ä–æ–±–ª–µ–º—ã, –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏, —Ä–∏—Å–∫–∏. –î–ª—è –∫–∞–∂–¥–æ–π –ø—Ä–æ–±–ª–µ–º—ã –æ–±—ä—è—Å–Ω—è–π: –ø–æ—á–µ–º—É —ç—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞ + —á—Ç–æ –¥–µ–ª–∞—Ç—å –¥–∞–ª—å—à–µ. –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—é: P1 (–∫—Ä–∏—Ç–∏—á–Ω–æ), P2 (–≤–∞–∂–Ω–æ), P3 (–º–æ–∂–Ω–æ –æ—Ç–ª–æ–∂–∏—Ç—å)."

**Given** load_prompt function exists
**When** I create `call_gpt(prompt_file, user_message, context=None)` function in bot/agent.py
**Then** function loads system prompt from prompt_file
**And** constructs messages: [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_message}]
**And** if context provided: adds context to user_message
**And** calls `openai.ChatCompletion.create(model="gpt-4", messages=messages)`
**And** returns response.choices[0].message.content

**Given** call_gpt function exists
**When** OpenAI API call fails
**Then** function retries up to 3 times with exponential backoff (1s, 2s, 4s)
**And** if all retries fail: raises exception with error details
**And** logs error to EventLog

**Given** GPT integration works
**When** I test with prompt_file='analyst', user_message='–°–æ–∑–¥–∞–π —Å–ø—Ä–∞–≤–∫—É –ø–æ –ø—Ä–æ–µ–∫—Ç—É X'
**Then** GPT returns structured response following analyst prompt style

### Story 2.4: Radar Scoring Engine

As Artem,
I want the system to automatically score projects and features to identify "what's burning",
So that I can see top problems instantly.

**Acceptance Criteria:**

**Given** I create services/radar.py
**When** I create `RadarScorer` class
**Then** class has methods: `score_feature(feature)`, `score_project(project)`, `get_top_issues(user_id, limit=3)`

**Given** RadarScorer exists
**When** I implement `score_feature(feature)` method
**Then** method calculates score based on:
- Feature.status == 'blocked' ‚Üí +50 points
- Dependency exists where this feature is blocked ‚Üí +30 points
- Feature linked to Release with target_date ‚â§ 7 days ‚Üí +40 points
- Feature.status == 'in_progress' for > 14 days ‚Üí +20 points
**And** returns {'score': int, 'reasons': [list of why], 'next_steps': [list of actions]}

**Given** score_feature method exists
**When** feature is blocked and linked to release in 5 days
**Then** score = 50 (blocked) + 40 (release soon) = 90
**And** reasons = ['–§–∏—á–∞ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞', '–†–µ–ª–∏–∑ —á–µ—Ä–µ–∑ 5 –¥–Ω–µ–π']
**And** next_steps = ['–†–∞–∑–±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å —Ñ–∏—á—É', '–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏']

**Given** RadarScorer exists
**When** I implement `get_top_issues(user_id, limit=3)` method
**Then** method gets active_project_id from UserContext
**And** if active_project_id: scores all features in that project
**And** if active_project_id is NULL: scores all features across all projects
**And** sorts by score descending
**And** returns top N items with {feature, project, score, reasons, next_steps}

**Given** multiple features with different scores exist
**When** I call `get_top_issues(user_id, limit=3)`
**Then** returns exactly 3 highest-scoring items
**And** each item includes full explainability (reasons + next_steps)

### Story 2.5: "–ß—Ç–æ –≥–æ—Ä–∏—Ç?" Command with Explainability

As Artem,
I want to ask "–ß—Ç–æ –≥–æ—Ä–∏—Ç?" and see Top-3 problems with explanations,
So that I instantly know what needs attention.

**Acceptance Criteria:**

**Given** NLU parser exists
**When** transcript is "–ß—Ç–æ –≥–æ—Ä–∏—Ç?"
**Then** parser returns {'command': 'radar_burning'}

**Given** radar_burning command identified
**When** I create `handle_radar_burning(user_id)` in bot/handlers/commands.py
**Then** function calls RadarScorer.get_top_issues(user_id, limit=3)
**And** formats response with GPT using prompt='risk_manager'

**Given** RadarScorer returns 3 items
**When** I format response
**Then** response structure is:
```
üî• –ß—Ç–æ –≥–æ—Ä–∏—Ç (Top-3):

1. –§–∏—á–∞: {feature_name} (–ü—Ä–æ–µ–∫—Ç: {project_name})
   –ü–æ—á–µ–º—É: {reasons joined}
   –ß—Ç–æ –¥–µ–ª–∞—Ç—å: {next_steps joined}
   [–ü–æ–¥—Ä–æ–±–Ω–µ–µ] [–ò—Å–ø—Ä–∞–≤–∏—Ç—å]

2. ...
3. ...
```

**Given** active project is "Mobile App"
**When** I say "–ß—Ç–æ –≥–æ—Ä–∏—Ç?"
**Then** bot shows Top-3 problems only from "Mobile App" project
**And** response starts with "–ö–æ–Ω—Ç–µ–∫—Å—Ç: –ü—Ä–æ–µ–∫—Ç Mobile App"

**Given** no active project (context is NULL)
**When** I say "–ß—Ç–æ –≥–æ—Ä–∏—Ç?"
**Then** bot shows Top-3 problems across ALL projects
**And** each item shows project name

**Given** no problems found (all scores are 0)
**When** I say "–ß—Ç–æ –≥–æ—Ä–∏—Ç?"
**Then** bot responds: "‚úÖ –í—Å—ë —Å–ø–æ–∫–æ–π–Ω–æ! –ù–µ—Ç –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º."

### Story 2.6: Inline Buttons for Quick Actions

As Artem,
I want to see inline buttons with Radar responses for quick navigation,
So that I can drill down without typing.

**Acceptance Criteria:**

**Given** python-telegram-bot supports InlineKeyboardMarkup
**When** I create `create_inline_buttons(button_configs)` helper in bot/handlers/commands.py
**Then** function takes list of {text, callback_data} dicts
**And** returns InlineKeyboardMarkup with buttons

**Given** Radar response is generated
**When** I add inline buttons to each Top-3 item
**Then** buttons are: [üìä –ü–æ–¥—Ä–æ–±–Ω–µ–µ] [‚ùì –ü–æ—á–µ–º—É?] [‚ñ∂Ô∏è –°–ª–µ–¥—É—é—â–µ–µ]
**And** callback_data for [–ü–æ–¥—Ä–æ–±–Ω–µ–µ] = 'radar_detail_{feature_id}'
**And** callback_data for [–ü–æ—á–µ–º—É?] = 'radar_explain_{feature_id}'
**And** callback_data for [–°–ª–µ–¥—É—é—â–µ–µ] = 'radar_next_{current_index}'

**Given** inline buttons are created
**When** I create bot/handlers/callbacks.py with callback query handler
**Then** handler function `handle_callback(update, context)` exists

**Given** callback handler exists
**When** callback_data is 'radar_detail_{feature_id}'
**Then** bot fetches full Feature details from database
**And** shows: name, description, status, status_reason, assigned_teams, dependencies, created_at, updated_at
**And** adds buttons: [–ò—Å—Ç–æ—Ä–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π] [–ù–∞–∑–∞–¥ –∫ Radar]

**Given** callback_data is 'radar_explain_{feature_id}'
**When** callback is triggered
**Then** bot calls GPT with prompt='risk_manager' and context=feature details
**And** GPT explains in detail why this is a problem and what to do

**Given** I click [–ü–æ–¥—Ä–æ–±–Ω–µ–µ] button on Radar item #1
**Then** bot edits original message to show detailed view
**And** I can click [–ù–∞–∑–∞–¥ –∫ Radar] to return to Top-3 list

### Story 2.7: "–ì–¥–µ —Ä–∏—Å–∫?" and "–ß—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å?" Commands

As Artem,
I want additional Radar views for risks and recent changes,
So that I have multiple perspectives on project health.

**Acceptance Criteria:**

**Given** NLU parser exists
**When** transcript is "–ì–¥–µ —Ä–∏—Å–∫?"
**Then** parser returns {'command': 'radar_risks'}

**Given** I need to store risks
**When** I create models/risk.py (if not exists from Story 1.2)
**Then** Risk model has fields: id (PK), project_id (FK), feature_id (FK, nullable), severity (String: low|medium|high|critical), description (Text), mitigation (Text, nullable), created_at

**Given** radar_risks command identified
**When** I create `handle_radar_risks(user_id)` in bot/handlers/commands.py
**Then** function queries Risk table for active project (or all if no context)
**And** sorts by severity (critical > high > medium > low)
**And** returns Top-3 with explainability

**Given** NLU parser exists
**When** transcript is "–ß—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å?"
**Then** parser returns {'command': 'radar_changes'}

**Given** radar_changes command identified
**When** I create `handle_radar_changes(user_id)`
**Then** function queries EventLog for last 24 hours in active project
**And** filters for significant events: project_created, feature_created, feature_status_updated, dependency_created, risk_created
**And** groups by entity and shows Top-5 most recent changes

**Given** I say "–ß—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å?" in project with recent activity
**Then** bot responds:
```
üìÖ –ò–∑–º–µ–Ω–µ–Ω–∏—è –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞ (–ü—Ä–æ–µ–∫—Ç: Mobile App):

1. –§–∏—á–∞ "–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏": backlog ‚Üí in_progress (2 —á–∞—Å–∞ –Ω–∞–∑–∞–¥)
2. –ù–æ–≤–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å: "–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è" –±–ª–æ–∫–∏—Ä—É–µ—Ç "–¥–∞—à–±–æ—Ä–¥" (5 —á–∞—Å–æ–≤ –Ω–∞–∑–∞–¥)
3. –ù–æ–≤—ã–π —Ä–∏—Å–∫ –¥–æ–±–∞–≤–ª–µ–Ω: "–ó–∞–¥–µ—Ä–∂–∫–∞ API" (severity: high) (8 —á–∞—Å–æ–≤ –Ω–∞–∑–∞–¥)
...
```

---

## Epic 3: Workflow Automation ‚Äî –í—Å—Ç—Ä–µ—á–∏, –ø–æ—Ä—É—á–µ–Ω–∏—è, –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è CEO

**Goal:** Artem –º–æ–∂–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä—É—Ç–∏–Ω—É: –Ω–∞–¥–∏–∫—Ç–æ–≤–∞—Ç—å –ø—Ä–æ—Ç–æ–∫–æ–ª –≤—Å—Ç—Ä–µ—á–∏ (—Å–∏—Å—Ç–µ–º–∞ –∏–∑–≤–ª–µ—á—ë—Ç —Ä–µ—à–µ–Ω–∏—è/–ø–æ—Ä—É—á–µ–Ω–∏—è), –ø–æ–ª—É—á–∏—Ç—å –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è –æ –¥–µ–¥–ª–∞–π–Ω–∞—Ö, –∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫—Ä–∞—Å–∏–≤—ã–π HTML-–ª–µ–Ω–¥–∏–Ω–≥ –¥–ª—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏ CEO.

### Story 3.1: Meeting Protocol Extraction

As Artem,
I want to dictate a meeting protocol and have the system extract decisions, assignments, and risks,
So that I don't manually structure meeting notes.

**Acceptance Criteria:**

**Given** I need to store meetings and related entities
**When** I create models/meeting.py, models/decision.py (if not exist)
**Then** Meeting model: id, project_id (FK), title, date, participants (Text), created_at
**And** Decision model: id, meeting_id (FK), project_id (FK), description (Text), created_at

**Given** NLU parser exists
**When** transcript starts with "–ü—Ä–æ—Ç–æ–∫–æ–ª –≤—Å—Ç—Ä–µ—á–∏:" or "–í—Å—Ç—Ä–µ—á–∞:"
**Then** parser returns {'command': 'meeting_protocol', 'full_transcript': text}

**Given** meeting_protocol command identified
**When** I create `handle_meeting_protocol(transcript, user_id)` in bot/handlers/commands.py
**Then** function creates Meeting entity in database
**And** calls GPT with prompt='meeting_secretary' and full transcript

**Given** I create bot/prompts/meeting_secretary.txt
**Then** prompt instructs GPT: "Extract from meeting notes: 1) Decisions (what was decided), 2) Assignments (who does what by when), 3) Risks (what concerns were raised). Return JSON: {decisions: [], assignments: [], risks: []}"

**Given** GPT extracts structured data
**When** response is received
**Then** function parses JSON
**And** creates Decision entities for each decision
**And** creates Assignment entities for each assignment
**And** creates Risk entities for each risk
**And** all entities linked to meeting_id and project_id

**Given** I dictate: "–ü—Ä–æ—Ç–æ–∫–æ–ª –≤—Å—Ç—Ä–µ—á–∏: –†–µ—à–∏–ª–∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å MVP —á–µ—Ä–µ–∑ 2 –Ω–µ–¥–µ–ª–∏. –û–ª–µ–≥ –¥–µ–ª–∞–µ—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é –¥–æ –ø—è—Ç–Ω–∏—Ü—ã. –†–∏—Å–∫: –Ω–µ—Ö–≤–∞—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è."
**When** processing completes
**Then** Meeting created with title extracted by GPT
**And** 1 Decision created: "–ó–∞–ø—É—Å—Ç–∏—Ç—å MVP —á–µ—Ä–µ–∑ 2 –Ω–µ–¥–µ–ª–∏"
**And** 1 Assignment created: assignee="–û–ª–µ–≥", title="–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è", deadline=–ø—è—Ç–Ω–∏—Ü–∞
**And** 1 Risk created: description="–Ω–µ—Ö–≤–∞—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è", severity="medium"
**And** bot responds: "‚úÖ –ü—Ä–æ—Ç–æ–∫–æ–ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω: 1 —Ä–µ—à–µ–Ω–∏–µ, 1 –ø–æ—Ä—É—á–µ–Ω–∏–µ, 1 —Ä–∏—Å–∫ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω—ã"

### Story 3.2: Assignments & Reminders with APScheduler

As Artem,
I want to create assignments with deadlines and receive reminders,
So that I never miss important tasks.

**Acceptance Criteria:**

**Given** Assignment model exists
**When** I verify schema
**Then** Assignment has: id, project_id, title, assignee, deadline (DateTime), priority (String), source_type (leader|meeting|self), source_person_id (String, nullable), inbox_type (general|leader), reminder_times (JSON array), created_at

**Given** NLU parser exists
**When** transcript is "–ù–∞–ø–æ–º–Ω–∏ –º–Ω–µ –ø—Ä–æ –æ—Ç—á—ë—Ç —á–µ—Ä–µ–∑ 2 —á–∞—Å–∞"
**Then** parser returns {'command': 'create_reminder', 'task': '–æ—Ç—á—ë—Ç', 'reminder_time': '2 hours'}

**Given** create_reminder command identified
**When** I create `handle_create_reminder(task, reminder_time, user_id)`
**Then** function creates Assignment with deadline=now+2hours, assignee=user_id
**And** calculates reminder_times (e.g., [deadline-2hours, deadline-24hours] if deadline > 24h)
**And** stores in Assignment.reminder_times as JSON array

**Given** I create jobs/scheduler.py with APScheduler setup
**When** scheduler is initialized
**Then** SQLAlchemyJobStore is configured with DATABASE_URL
**And** BackgroundScheduler is started

**Given** scheduler is running
**When** I create jobs/reminders.py with `check_reminders()` function
**Then** function queries Assignments where deadline is upcoming
**And** checks if now >= any reminder_time in reminder_times array
**And** sends Telegram message for due reminders

**Given** scheduler setup exists
**When** I add interval job to check reminders every minute
**Then** `scheduler.add_job(check_reminders, 'interval', minutes=1)` is configured

**Given** Assignment exists with deadline in 2 hours and reminder_times=[now+2hours]
**When** 2 hours pass and scheduler runs check_reminders
**Then** bot sends Telegram message: "‚è∞ –ù–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ: –æ—Ç—á—ë—Ç (–¥–µ–¥–ª–∞–π–Ω —á–µ—Ä–µ–∑ 2 —á–∞—Å–∞)"
**And** removes that reminder_time from array to avoid duplicate

**Given** multiple assignments have reminders due
**When** check_reminders runs
**Then** sends separate message for each assignment
**And** messages include: task title, deadline, [–í—ã–ø–æ–ª–Ω–µ–Ω–æ] [–û—Ç–ª–æ–∂–∏—Ç—å] buttons

### Story 3.3: Leader Tasks Inbox

As Artem,
I want to create assignments that came from my manager with special handling,
So that I never miss CEO requests.

**Acceptance Criteria:**

**Given** Assignment model has inbox_type field
**When** NLU parser identifies leader task
**Then** transcript pattern: "–û—Ç –°–µ—Ä–≥–µ—è: –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –æ—Ç—á—ë—Ç –∫ –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫—É" or "CEO –ø—Ä–æ—Å–∏—Ç: –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤"
**And** parser returns {'command': 'leader_task', 'leader_name': '–°–µ—Ä–≥–µ—è', 'task': text, 'deadline': extracted}

**Given** leader_task command identified
**When** I create `handle_leader_task(leader_name, task, deadline, user_id)`
**Then** function creates Assignment with source_type='leader', source_person_id=leader_name, inbox_type='leader', priority='P1'
**And** EventLog records: action='leader_task_created'

**Given** Leader task exists
**When** Radar scoring runs
**Then** Leader tasks (inbox_type='leader') get +100 bonus points
**And** they never get suppressed (always appear in Top-3 if deadline ‚â§ 48 hours)

**Given** I say "–û—Ç CEO: –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—é –∫ –ø—è—Ç–Ω–∏—Ü–µ"
**Then** Assignment created with inbox_type='leader', source_person_id='CEO', priority='P1'
**And** bot responds: "‚úÖ –ü–æ—Ä—É—á–µ–Ω–∏–µ –æ—Ç —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–æ: '–ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—é' (–¥–µ–¥–ª–∞–π–Ω: –ø—è—Ç–Ω–∏—Ü–∞, –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: P1)"
**And** reminder set for 24 hours before deadline

### Story 3.4: HTML Template Foundation

As Artem,
I want Jinja2 templates with Tailwind CSS for rendering beautiful artifacts,
So that I can present polished reports to CEO.

**Acceptance Criteria:**

**Given** I create templates/base.html
**Then** template includes: HTML5 structure, Tailwind CSS CDN link, responsive meta tags, base content block

**Given** base.html exists
**When** I create templates/radar_report.html extending base.html
**Then** template has sections: header with project name, Top-3 issues list, explainability for each, footer with timestamp

**Given** I create services/html_render.py
**When** I create `HTMLRenderer` class
**Then** class has method: `render_artifact(artifact_type, data)`

**Given** HTMLRenderer exists
**When** I implement `render_artifact('radar_report', data)` method
**Then** method loads radar_report.html template
**And** renders with Jinja2 using data
**And** returns HTML string

**Given** HTML is rendered
**When** I create `save_artifact(html_content, artifact_type, project_id, title)` method
**Then** method generates random access_token (uuid4)
**And** saves HTML to /static/artifacts/{access_token}.html
**And** creates Artifact record in database with rendered_url=/static/artifacts/{access_token}.html, expires_at=now+7days

**Given** artifact is saved
**When** I access URL /static/artifacts/{access_token}.html
**Then** HTML file is served by Flask static files
**And** page renders beautifully with Tailwind CSS

**Given** artifact expires_at < now
**When** cleanup job runs (deferred to Story 3.7)
**Then** file is deleted from /static/artifacts/
**And** Artifact.rendered_url is set to NULL

### Story 3.5: Meeting Prep Artifact

As Artem,
I want to say "–ü–æ–¥–≥–æ—Ç–æ–≤—å –∫ –≤—Å—Ç—Ä–µ—á–µ —Å –û–ª–µ–≥–æ–º" and receive a brief with status, questions, and risks,
So that I'm always prepared in 2 minutes.

**Acceptance Criteria:**

**Given** NLU parser exists
**When** transcript is "–ü–æ–¥–≥–æ—Ç–æ–≤—å –∫ –≤—Å—Ç—Ä–µ—á–µ —Å –û–ª–µ–≥–æ–º –ø–æ –ø—Ä–æ–µ–∫—Ç—É Mobile App"
**Then** parser returns {'command': 'meeting_prep', 'person': '–û–ª–µ–≥–æ–º', 'project_name': 'Mobile App'}

**Given** meeting_prep command identified
**When** I create `handle_meeting_prep(person, project_id, user_id)`
**Then** function gathers data: recent feature statuses, open assignments, recent decisions, active risks
**And** calls GPT with prompt='analyst' and context data
**And** GPT generates structured prep: Project status summary, Key questions to ask (3-5), Critical risks to discuss (Top-3), Recent changes

**Given** GPT returns meeting prep content
**When** I create templates/meeting_prep.html
**Then** template displays: Header with meeting title, Status section, Questions list, Risks section, Recent changes timeline

**Given** meeting prep is generated
**When** rendering completes
**Then** HTMLRenderer.render_artifact('meeting_prep', data) is called
**And** artifact saved to /static/artifacts/{token}.html
**And** Artifact record created with type='prep'

**Given** I say "–ü–æ–¥–≥–æ—Ç–æ–≤—å –∫ –≤—Å—Ç—Ä–µ—á–µ —Å –û–ª–µ–≥–æ–º –ø–æ –ø—Ä–æ–µ–∫—Ç—É Mobile App"
**Then** bot responds: "üìã Meeting Prep –≥–æ—Ç–æ–≤! [–û—Ç–∫—Ä—ã—Ç—å –ª–µ–Ω–¥–∏–Ω–≥] (link: /static/artifacts/{token}.html)"
**And** link expires in 7 days

### Story 3.6: Project Brief Artifact for CEO

As Artem,
I want to generate a beautiful project brief HTML to show to CEO,
So that I look professional and well-prepared.

**Acceptance Criteria:**

**Given** NLU parser exists
**When** transcript is "–°–ø—Ä–∞–≤–∫–∞ –ø–æ –ø—Ä–æ–µ–∫—Ç—É Mobile App"
**Then** parser returns {'command': 'project_brief', 'project_name': 'Mobile App'}

**Given** project_brief command identified
**When** I create `handle_project_brief(project_id, user_id)`
**Then** function gathers: Project description, Key features (all features grouped by status), Releases with target dates, Recent decisions, Active risks, Metrics (total features, completion %, blocked count)
**And** calls GPT with prompt='analyst' to create executive summary

**Given** I create templates/project_brief.html
**Then** template includes: Hero section with project name, Executive summary (GPT-generated), Metrics cards (features count, completion %, risks), Features table grouped by status, Timeline with releases, Risks section with severity badges

**Given** Tailwind CSS is used
**When** project_brief.html renders
**Then** design is professional: gradient headers, card layouts, color-coded status badges (green=done, yellow=in_progress, red=blocked), responsive grid

**Given** I say "–°–ø—Ä–∞–≤–∫–∞ –ø–æ –ø—Ä–æ–µ–∫—Ç—É Mobile App"
**Then** bot generates HTML artifact
**And** responds: "üìä –°–ø—Ä–∞–≤–∫–∞ –ø–æ –ø—Ä–æ–µ–∫—Ç—É –≥–æ—Ç–æ–≤–∞! [–û—Ç–∫—Ä—ã—Ç—å –ª–µ–Ω–¥–∏–Ω–≥] (–ø—Ä–∏–≤–∞—Ç–Ω–∞—è —Å—Å—ã–ª–∫–∞, TTL=7 –¥–Ω–µ–π)"
**And** I can open link and show beautiful report to CEO

### Story 3.7: Artifact Cleanup & Management

As Artem,
I want old artifacts (> 7 days) to be automatically deleted,
So that storage doesn't grow indefinitely.

**Acceptance Criteria:**

**Given** APScheduler is configured
**When** I create jobs/artifact_cleanup.py with `cleanup_expired_artifacts()` function
**Then** function queries Artifact table where expires_at < now
**And** deletes files from /static/artifacts/{access_token}.html
**And** sets Artifact.rendered_url = NULL, rendered_html = NULL

**Given** cleanup function exists
**When** I add daily cron job
**Then** `scheduler.add_job(cleanup_expired_artifacts, 'cron', hour=2)` runs every day at 2 AM

**Given** artifact created 8 days ago (expired)
**When** cleanup job runs
**Then** HTML file deleted from /static/artifacts/
**And** Artifact record still exists but rendered_url is NULL
**And** EventLog records: action='artifact_expired', entity_id=artifact_id

**Given** I try to access expired artifact URL
**When** file doesn't exist
**Then** Flask returns 404 or custom "Artifact expired" page

---

## Epic 4: Autonomous Research ‚Äî –î–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π + Production

**Goal:** Artem –º–æ–∂–µ—Ç –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞—Ç—å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —Å–∏—Å—Ç–µ–º–µ ("–ù–µ —Ç—Ä–µ–≤–æ–∂—å –º–µ–Ω—è") –∏ –ø–æ–ª—É—á–∏—Ç—å –≥–æ—Ç–æ–≤—ã–π one-pager —É—Ç—Ä–æ–º, –∞ —Ç–∞–∫–∂–µ –∏–º–µ—Ç—å —Ä–∞–±–æ—Ç–∞—é—â–∏–π 24/7 –±–æ—Ç –Ω–∞ Railway.

### Story 4.1: Background Research Task

As Artem,
I want to delegate research tasks to the bot and have it work autonomously,
So that I get structured results without my involvement.

**Acceptance Criteria:**

**Given** NLU parser exists
**When** transcript is "–ò—Å—Å–ª–µ–¥—É–π: –ª—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ real-time collaboration, –Ω–µ —Ç—Ä–µ–≤–æ–∂—å –º–µ–Ω—è"
**Then** parser returns {'command': 'research_task', 'query': '–ª—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ real-time collaboration', 'autonomous': true}

**Given** research_task command identified
**When** I create `handle_research_task(query, user_id, project_id)`
**Then** function creates ResearchTask model (new) in database
**And** schedules APScheduler job to run research in background

**Given** I create models/research_task.py
**Then** ResearchTask model has: id, project_id (FK), query (Text), status (pending|in_progress|completed|failed), result_artifact_id (FK to Artifact, nullable), created_at, completed_at (nullable)

**Given** research task is scheduled
**When** APScheduler triggers job
**Then** job calls `execute_research(research_task_id)` function

**Given** I create `execute_research(research_task_id)` in jobs/research.py
**When** function runs
**Then** updates ResearchTask.status = 'in_progress'
**And** calls GPT with prompt='researcher' and query
**And** GPT performs web search (using GPT browsing or search plugin if available, or mock for MVP)
**And** GPT generates one-pager with 7 sections: Question, Alternatives (3-5 options), Comparison table, Recommendation, Risks, Assumptions, Next Steps, Sources

**Given** research completes
**When** one-pager is generated
**Then** creates Artifact with type='research', content=one_pager JSON
**And** renders HTML using templates/research_onepager.html
**And** updates ResearchTask.status='completed', result_artifact_id=artifact_id, completed_at=now

**Given** research completes
**When** I create notification logic
**Then** bot sends Telegram message: "üî¨ –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: '{query}' [–û—Ç–∫—Ä—ã—Ç—å one-pager] (link)"

**Given** I say "–ò—Å—Å–ª–µ–¥—É–π: –ª—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ real-time collaboration, –Ω–µ —Ç—Ä–µ–≤–æ–∂—å –º–µ–Ω—è"
**Then** bot responds: "üî¨ –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∑–∞–ø—É—â–µ–Ω–æ. –ö–æ–≥–¥–∞ –∑–∞–∫–æ–Ω—á—É, –ø—Ä–∏—à–ª—é —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ."
**And** research runs in background (5-15 minutes)
**And** I receive notification with link to HTML one-pager

### Story 4.2: Research One-Pager Template

As Artem,
I want research results presented as beautiful HTML one-pagers,
So that I can quickly review and make decisions.

**Acceptance Criteria:**

**Given** I create templates/research_onepager.html
**Then** template structure includes:
- Header: Research question
- Section 1: Question restatement
- Section 2: Alternatives (cards with pros/cons)
- Section 3: Comparison table (criteria vs alternatives)
- Section 4: Recommendation (highlighted, with reasoning)
- Section 5: Risks (color-coded by severity)
- Section 6: Assumptions (listed)
- Section 7: Next Steps (actionable items)
- Section 8: Sources (links to references)

**Given** Tailwind CSS is used
**When** research_onepager.html renders
**Then** design is professional: header with gradient, card-based alternatives, comparison table with borders, highlighted recommendation box, color-coded risks (red=high, yellow=medium, green=low)

**Given** research data is passed to template
**When** rendering occurs
**Then** all 7 sections populated from JSON data
**And** sources rendered as clickable links
**And** responsive design works on mobile

### Story 4.3: Railway Deployment Setup

As Artem,
I want to deploy the bot to Railway so it runs 24/7,
So that I can use it from anywhere anytime.

**Acceptance Criteria:**

**Given** code is in GitHub repository
**When** I connect Railway to GitHub repo
**Then** Railway detects Python app automatically

**Given** Railway project is created
**When** I configure environment variables in Railway dashboard
**Then** variables set: TELEGRAM_TOKEN, OPENAI_API_KEY, YOUR_TELEGRAM_ID, ENVIRONMENT=production
**And** DATABASE_URL automatically provided by Railway PostgreSQL

**Given** I create Procfile or railway.toml
**Then** start command is: `python app.py`

**Given** deployment configuration exists
**When** I push code to GitHub
**Then** Railway auto-deploys
**And** runs migrations: `alembic upgrade head`
**And** starts bot in webhook mode (ENVIRONMENT=production triggers webhook instead of polling)

**Given** bot is deployed on Railway
**When** I send message to Telegram bot
**Then** webhook receives update from Telegram
**And** bot processes and responds
**And** response time < 2 seconds

### Story 4.4: Webhook Mode Configuration

As Artem,
I want the bot to use webhook mode in production instead of polling,
So that it's more efficient and reliable.

**Acceptance Criteria:**

**Given** ENVIRONMENT=production in .env
**When** app.py initializes
**Then** bot uses webhook mode instead of polling

**Given** I create `setup_webhook()` function in app.py
**When** ENVIRONMENT=production
**Then** function sets webhook URL: `bot.set_webhook(url=f'https://{railway_domain}/webhook/{TELEGRAM_TOKEN}')`

**Given** I create webhook route in app.py (Flask)
**When** route `/webhook/{token}` receives POST request
**Then** verifies token matches TELEGRAM_TOKEN
**And** processes update from Telegram
**And** returns 200 OK

**Given** webhook is set up
**When** Railway provides HTTPS domain automatically
**Then** Telegram delivers updates to webhook URL
**And** bot processes without polling

### Story 4.5: Production Testing & Bug Fixes

As Artem,
I want to test the bot in production and fix any bugs found,
So that it's stable and reliable for daily use.

**Acceptance Criteria:**

**Given** bot is deployed on Railway
**When** I test all core commands: /start, voice messages, "–°–æ–∑–¥–∞–π –ø—Ä–æ–µ–∫—Ç", "–ß—Ç–æ –≥–æ—Ä–∏—Ç?", "–ü–æ–¥–≥–æ—Ç–æ–≤—å –∫ –≤—Å—Ç—Ä–µ—á–µ"
**Then** all commands work correctly
**And** response times are acceptable (< 3 seconds for voice, < 1 second for text)

**Given** testing reveals bugs
**When** I report bug to Claude
**Then** Claude fixes bug in code
**And** pushes fix to GitHub
**And** Railway auto-deploys new version

**Given** I test Radar with real data (10+ projects, 50+ features)
**When** I say "–ß—Ç–æ –≥–æ—Ä–∏—Ç?"
**Then** Radar returns Top-3 in < 10 seconds
**And** results are accurate (blocked features, deadline pressure, etc.)

**Given** I test reminders
**When** I create assignment with reminder in 1 hour
**Then** APScheduler sends reminder exactly on time
**And** reminder message includes [–í—ã–ø–æ–ª–Ω–µ–Ω–æ] button

**Given** I test HTML artifacts
**When** I generate meeting prep and project brief
**Then** HTML renders correctly on mobile and desktop
**And** Tailwind CSS styles load from CDN
**And** private links work and expire after 7 days

**Given** all features tested and working
**When** I use bot for 3 consecutive days
**Then** no crashes, no missed commands, all data persists
**And** Railway free tier hours sufficient (< 500 hours/month usage)
